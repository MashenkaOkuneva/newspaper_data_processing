{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import worker_xml\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "from itertools import repeat\n",
    "from numbers_delete import numbers_delete\n",
    "from Split_articles import split_mult_art\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of cores to use\n",
    "NUM_CORE = mp.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dpa Data (1991 - 2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with unpacked articles\n",
    "path = r'E:\\\\Userhome\\\\jbaer\\\\dpa_unpacked'\n",
    "folder_list = []\n",
    "\n",
    "# 2 folders\n",
    "for fol in [fol for fol in os.listdir(path)]:\n",
    "\n",
    "    # Within each folder: folders for different years\n",
    "    for f in [f for f in os.listdir(path + '\\\\' + fol)]:\n",
    "        folder_list.append(path + '\\\\' + fol + '\\\\' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a path to the folder for storing results\n",
    "PATH = r'E:\\\\Userhome\\\\jbaer\\\\Media Tenor Results'\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:03:54.342357\n"
     ]
    }
   ],
   "source": [
    "# Use the 'worker_xml' function to load articles\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    df_list = pool.map(worker_xml.worker_xml, folder_list)\n",
    "    data = pd.concat(df_list)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles before filtering: 7539874\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles before filtering:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('dpa_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('dpa_raw.csv')\n",
    "#data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out articles with less than 75 words\n",
    "data = data[pd.to_numeric(data['wordcount']) >= 75]\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out insignificant articles based on keywords, genres etc.\n",
    "fil_titles = '''Edelmetallpreise|Tageskalender|Tabelle|SPORT|SPORT\\:|\n",
    "                Sport|Berichtigung|Sortenkurse|Devisenkurse|Impressum|Testmeldung|\n",
    "                Kurse A|Kurse B|Kurse C|DGAP-DD'''\n",
    "data.drop(data[data['title'].str.contains(fil_titles)].index, inplace=True)\n",
    "\n",
    "fil_genres = '''Tabelle|Historisches|Achtung|Sport|SPORT'''\n",
    "data.drop(data[data['genre'].str.contains(fil_genres)].index, inplace=True)\n",
    "\n",
    "fil_keywords = '''Sport|Redaktionshinweis|SUM|DGAP|Sport|SPORT|SPO'''\n",
    "data.drop(data[data['keywords'].str.contains(fil_keywords)].index, inplace=True)\n",
    "\n",
    "data.drop(data[data['rubrics'].str.contains('iq')].index, inplace=True)\n",
    "\n",
    "fil_texts = '''Schalterverkaufskurse:|dpa-news.de'''\n",
    "data.drop(data[data['texts'].str.contains(fil_texts)].index, inplace=True)\n",
    "\n",
    "data.drop(data[data['source'] == 'dpa-frei\\dpa-wahl'].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Filter out articles based on keywords which are specific to the economic news\n",
    "keyword_clean = '''Kurse|KURSE|kurse|Börse International|Terminbörse|Finanzmärkte International'''\n",
    "WiPo = data[data['topic'] == 'WiPo'] \n",
    "data.drop(WiPo[WiPo['keywords'].str.contains(keyword_clean)].index, inplace = True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free memory space to avoid memory errors\n",
    "del WiPo\n",
    "del df_list\n",
    "\n",
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 'numbers_delete' function to filter out economic articles with a high share of numbers in them\n",
    "delete_index = numbers_delete(data)\n",
    "data.drop(delete_index, inplace = True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store entries potentially consisting of multiple articles separately\n",
    "# as 'mult art' \n",
    "s_mult_art = '''dpa-Nachrichtenüberblick|Nachrichtenüberblick|\n",
    "                Vorschau|vorschau|VORSCHAU|Tagesvorschau|\n",
    "                dpa-Tagesvorschau'''\n",
    "\n",
    "mult_art = data[data['title'].str.contains(s_mult_art)]\n",
    "mult_art = mult_art.append(data[data['keywords'].str.contains(s_mult_art)])\n",
    "mult_art = mult_art.append(data[data['genre'].str.contains(s_mult_art)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete 'mult_art' from the original data\n",
    "data.drop(data[data['title'].str.contains(s_mult_art)].index, inplace=True)\n",
    "data.drop(data[data['keywords'].str.contains(s_mult_art)].index, inplace=True)\n",
    "data.drop(data[data['genre'].str.contains(s_mult_art)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the 'split_mult_art' function to split up entries in \n",
    "# 'mult_art' and append the resulting new articles to the data\n",
    "data = data.append(split_mult_art(mult_art))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free memory space to avoid memory errors\n",
    "del mult_art\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles after first filtering steps: 5804758\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of articles after first filtering steps:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('dpa_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('dpa_filter1_test.csv')\n",
    "#data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Based on Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into economic and finance articles\n",
    "afx = data[data['topic'] == 'afx']\n",
    "afx.reset_index(inplace=True, drop=True)\n",
    "\n",
    "WiPo = data[data['topic'] == 'WiPo'] \n",
    "WiPo.reset_index(inplace=True, drop=True)\n",
    "\n",
    "WiPo = WiPo.drop(columns=['index'])\n",
    "afx = afx.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of WiPo Articles: 3008508 , Number of afx Articles: 2796250\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of WiPo Articles:\", len(WiPo), \", Number of afx Articles:\", len(afx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save intermediate results\n",
    "WiPo.to_csv('dpa_WiPo_filter_test.csv')\n",
    "afx.to_csv('dpa_afx_filter_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free memory space to avoid memory errors\n",
    "del data\n",
    "del afx\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (8,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "WiPo = pd.read_csv('dpa_WiPo_filter1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Fuzzy Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:27:54.155425\n",
      "0:28:46.127699\n",
      "0:29:19.964563\n",
      "0:28:58.137109\n",
      "0:31:13.391723\n",
      "0:30:47.166563\n",
      "0:29:45.029791\n",
      "0:36:11.646510\n",
      "0:45:40.567644\n",
      "0:47:32.491350\n",
      "0:46:28.792219\n",
      "0:43:58.462043\n",
      "0:42:32.873097\n",
      "0:38:33.170213\n",
      "0:39:32.574870\n",
      "0:41:40.436872\n",
      "0:45:47.384667\n",
      "0:58:24.250584\n",
      "0:56:42.222056\n",
      "0:44:42.390548\n",
      "0:45:16.469658\n",
      "0:43:56.798871\n",
      "0:42:55.383620\n",
      "0:41:32.612163\n",
      "0:47:14.749925\n",
      "0:48:18.405921\n",
      "0:40:59.334162\n",
      "0:34:55.400031\n",
      "0:00:00.020233\n"
     ]
    }
   ],
   "source": [
    "# NOTE: I ignored the multiprocessing function to avoid memory issues\n",
    "\n",
    "import fuzzy_duplicates\n",
    "delete_indices = []\n",
    " \n",
    "for year, data_yearly in WiPo.groupby('year'):\n",
    "    \n",
    "    data_yearly = data_yearly.reset_index()\n",
    "    # Prepare inputs\n",
    "    inputs_year = []\n",
    "    inputs_month = []\n",
    "\n",
    "    for month in list(set(data_yearly['month'])):\n",
    "        inputs_year.append(year)\n",
    "        inputs_month.append(month)\n",
    "\n",
    "    inputs = list(zip(inputs_year, inputs_month, repeat(data_yearly)))\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "    \n",
    "    for inp in inputs:\n",
    "\n",
    "        delete_indices.append(fuzzy_duplicates.fuzzy_duplicates(inp))\n",
    "\n",
    "        # Apply function to all combinations of month-year in parallel\n",
    "        # if __name__ == \"__main__\":\n",
    "        # pool = mp.Pool(NUM_CORE)\n",
    "        # delete_indices.append(pool.map(fuzzy_duplicates.fuzzy_duplicates, inputs))\n",
    "        # pool.close()\n",
    "        # pool.join()\n",
    "\n",
    "    print(datetime.now()-startTime)\n",
    "\n",
    "merged = list(itertools.chain(*delete_indices))\n",
    "WiPo.drop(merged, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2651380"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(WiPo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete English Articles (optional for afx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:06.466414\n"
     ]
    }
   ],
   "source": [
    "# Import a function that outputs the indices of englisch articles\n",
    "import identify_eng\n",
    "\n",
    "# Delete all English articles from the data\n",
    "\n",
    "for year, data_yearly in afx.groupby('year'):\n",
    "    \n",
    "    startTime = datetime.now()\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        pool = mp.Pool(NUM_CORE)\n",
    "        split_dfs = np.array_split(data_yearly, NUM_CORE)\n",
    "        index_eng = pool.map(identify_eng.identify_eng, split_dfs)\n",
    "        index_eng = list(itertools.chain(*index_eng))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    print(datetime.now()-startTime)\n",
    "\n",
    "afx.drop(index_eng, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1827"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(afx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results\n",
    "WiPo.to_csv('dpa_WiPo_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results\n",
    "afx.to_csv('dpa_afx_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load function for cleaning dpa articles\n",
    "from clean_dp_articles import clean_dpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "#data = pd.read_csv('WiPo.csv', encoding = 'utf-8', index_col=False, dtype='unicode')\n",
    "#data.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CORE = mp.cpu_count()\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    # Split data into smaller dataframes\n",
    "    data_split = np.array_split(data, NUM_CORE)\n",
    "    # Reset index for each dataframe\n",
    "    [df.reset_index(inplace=True, drop=True) for df in data_split]\n",
    "    # Apply clean dpa function to each dataframe\n",
    "    data_intermediate = pool.map(clean_dpa, data_split)\n",
    "    data = pd.concat(data_intermediate)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
