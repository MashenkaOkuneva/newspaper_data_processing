{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import dpa_load\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "from itertools import repeat\n",
    "from ast import literal_eval\n",
    "import split_articles\n",
    "import numeric_articles\n",
    "import numeric_par\n",
    "import continue_articles\n",
    "import identify_ger\n",
    "import clean_tables\n",
    "# we import some functions from the Handelsblatt folder\n",
    "import sys\n",
    "sys.path.insert(1, os.getcwd().replace('dpa code', 'Handelsblatt'))\n",
    "import count_words_mp\n",
    "import correct_url\n",
    "import clean_dpa_articles\n",
    "import clean_dpa_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of cores to use\n",
    "NUM_CORE = mp.cpu_count()-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPA Data (1991 - 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deutsche PresseAgentur (DPA) is the Germany's biggest news agency which sells its news reports to the leading German newspapers. We believe that the data set has a high chance to be useful for economic forecasting because DPA produces information that is timely and has a large reach.\n",
    "\n",
    "We purchased DPA data in November 2019. The corpus consists of **7,539,874** articles from January 1991 to December 2018.\n",
    "\n",
    "The data set includes news from both dpa-Basisdienstes and dpa-afx Wirtschaftsnachrichten. The former one is the basic news service covering such topics as Economy, Politics, and  Finance. The second one was created in 1999. It specializes in financial news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read in the data by extracting the following XML elements:\n",
    "\n",
    "* title - article's title\n",
    "* text - text of the article\n",
    "* date - publication date\n",
    "* ressort - section (Politics vs Economy)\n",
    "* source/credit - source (dpa vs afx)\n",
    "* city - which city the news article refers to\n",
    "* genre - journalistic genre, e.g., chronology, story, table\n",
    "* wortanzahl - word count\n",
    "* keywords - keywords associated with an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with unpacked articles\n",
    "#path = r'E:\\\\Userhome\\\\jbaer\\\\dpa_unpacked'\n",
    "\n",
    "#path = r'G:\\\\Test\\\\Results\\\\dpa Raw Data\\\\dpa_unpacked'\n",
    "path = os.getcwd().replace('\\\\newspaper_data_processing\\\\dpa code', '') + '\\\\dpa_unpacked'\n",
    "\n",
    "folder_list = []\n",
    "\n",
    "# 2 folders for dpa and dpa-afx \n",
    "for fol in [fol for fol in os.listdir(path)]:\n",
    "\n",
    "    # Within each folder: folders for different years\n",
    "    for f in [f for f in os.listdir(path + '\\\\' + fol)]:\n",
    "        folder_list.append(path + '\\\\' + fol + '\\\\' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a path to the folder for storing results\n",
    "#PATH = r'G:\\\\Test\\\\Results'\n",
    "#os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:39:34.263517\n"
     ]
    }
   ],
   "source": [
    "# Use the 'dpa_load' function to load articles\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    df_list = pool.map(dpa_load.dpa_load, folder_list)\n",
    "    data = pd.concat(df_list)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7539874\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True) # reset the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>file</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>source</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>genre</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>topic</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schalck: Milliardenkredit sicherte Zahlungsfäh...</td>\n",
       "      <td>5739189.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Schalck-Golodkowski</td>\n",
       "      <td>Schalck: Milliardenkredit sicherte Zahlungsfäh...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td></td>\n",
       "      <td>218</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Berlin (dpa) - Nach Darstellung des früheren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tschads Regierung: Bevölkerung soll Waffen abl...</td>\n",
       "      <td>5739191.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Tschad</td>\n",
       "      <td>Tschads Regierung: Bevölkerung soll Waffen abl...</td>\n",
       "      <td>N'Djamena</td>\n",
       "      <td></td>\n",
       "      <td>75</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[N'Djamena (dpa) - Die tschadische Regierung h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Welajati: Iran bleibt bei einem Krieg am Golf ...</td>\n",
       "      <td>5739193.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise Iran</td>\n",
       "      <td>Welajati: Iran bleibt bei einem Krieg am Golf ...</td>\n",
       "      <td>Teheran</td>\n",
       "      <td></td>\n",
       "      <td>90</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Teheran (dpa) - Iran wird im Falle eines Krie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bush will offenbar seinen Außenminister erneut...</td>\n",
       "      <td>5739195.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise USA</td>\n",
       "      <td>Bush will offenbar seinen Außenminister erneut...</td>\n",
       "      <td>Washington</td>\n",
       "      <td></td>\n",
       "      <td>181</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Washington (dpa) - US-Präsident George Bush w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgenzusammenfassung Neue Runde diplomatische...</td>\n",
       "      <td>5739199.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise</td>\n",
       "      <td>Morgenzusammenfassung Neue Runde diplomatische...</td>\n",
       "      <td>Washington/Luxemburg</td>\n",
       "      <td></td>\n",
       "      <td>504</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Washington/Luxemburg (dpa) - Zwei Wochen vor ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts         file  day  month  \\\n",
       "0  Schalck: Milliardenkredit sicherte Zahlungsfäh...  5739189.xml    1      1   \n",
       "1  Tschads Regierung: Bevölkerung soll Waffen abl...  5739191.xml    1      1   \n",
       "2  Welajati: Iran bleibt bei einem Krieg am Golf ...  5739193.xml    1      1   \n",
       "3  Bush will offenbar seinen Außenminister erneut...  5739195.xml    1      1   \n",
       "4  Morgenzusammenfassung Neue Runde diplomatische...  5739199.xml    1      1   \n",
       "\n",
       "   year rubrics source             keywords  \\\n",
       "0  1991      pl    dpa  Schalck-Golodkowski   \n",
       "1  1991      pl    dpa               Tschad   \n",
       "2  1991      pl    dpa       Golfkrise Iran   \n",
       "3  1991      pl    dpa        Golfkrise USA   \n",
       "4  1991      pl    dpa            Golfkrise   \n",
       "\n",
       "                                               title                  city  \\\n",
       "0  Schalck: Milliardenkredit sicherte Zahlungsfäh...                Berlin   \n",
       "1  Tschads Regierung: Bevölkerung soll Waffen abl...             N'Djamena   \n",
       "2  Welajati: Iran bleibt bei einem Krieg am Golf ...               Teheran   \n",
       "3  Bush will offenbar seinen Außenminister erneut...            Washington   \n",
       "4  Morgenzusammenfassung Neue Runde diplomatische...  Washington/Luxemburg   \n",
       "\n",
       "  genre wordcount topic                                         paragraphs  \n",
       "0             218  WiPo  [Berlin (dpa) - Nach Darstellung des früheren ...  \n",
       "1              75  WiPo  [N'Djamena (dpa) - Die tschadische Regierung h...  \n",
       "2              90  WiPo  [Teheran (dpa) - Iran wird im Falle eines Krie...  \n",
       "3             181  WiPo  [Washington (dpa) - US-Präsident George Bush w...  \n",
       "4             504  WiPo  [Washington/Luxemburg (dpa) - Zwei Wochen vor ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dpa_raw.csv', encoding = 'utf-8', index_col = 0,  keep_default_na=False,\n",
    "                   dtype = {'rubrics': 'str', \n",
    "                            'source': 'str',\n",
    "                            'keywords': 'str',\n",
    "                            'title': 'str',\n",
    "                            'city': 'str',\n",
    "                            'genre': 'str',\n",
    "                            'wordcount': 'str'},\n",
    "                  converters = {'paragraphs': literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True) # reset the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>file</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>source</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>genre</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>topic</th>\n",
       "      <th>paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schalck: Milliardenkredit sicherte Zahlungsfäh...</td>\n",
       "      <td>5739189.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Schalck-Golodkowski</td>\n",
       "      <td>Schalck: Milliardenkredit sicherte Zahlungsfäh...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td></td>\n",
       "      <td>218</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Berlin (dpa) - Nach Darstellung des früheren ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tschads Regierung: Bevölkerung soll Waffen abl...</td>\n",
       "      <td>5739191.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Tschad</td>\n",
       "      <td>Tschads Regierung: Bevölkerung soll Waffen abl...</td>\n",
       "      <td>N'Djamena</td>\n",
       "      <td></td>\n",
       "      <td>75</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[N'Djamena (dpa) - Die tschadische Regierung h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Welajati: Iran bleibt bei einem Krieg am Golf ...</td>\n",
       "      <td>5739193.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise Iran</td>\n",
       "      <td>Welajati: Iran bleibt bei einem Krieg am Golf ...</td>\n",
       "      <td>Teheran</td>\n",
       "      <td></td>\n",
       "      <td>90</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Teheran (dpa) - Iran wird im Falle eines Krie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bush will offenbar seinen Außenminister erneut...</td>\n",
       "      <td>5739195.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise USA</td>\n",
       "      <td>Bush will offenbar seinen Außenminister erneut...</td>\n",
       "      <td>Washington</td>\n",
       "      <td></td>\n",
       "      <td>181</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Washington (dpa) - US-Präsident George Bush w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgenzusammenfassung Neue Runde diplomatische...</td>\n",
       "      <td>5739199.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise</td>\n",
       "      <td>Morgenzusammenfassung Neue Runde diplomatische...</td>\n",
       "      <td>Washington/Luxemburg</td>\n",
       "      <td></td>\n",
       "      <td>504</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Washington/Luxemburg (dpa) - Zwei Wochen vor ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts         file  day  month  \\\n",
       "0  Schalck: Milliardenkredit sicherte Zahlungsfäh...  5739189.xml    1      1   \n",
       "1  Tschads Regierung: Bevölkerung soll Waffen abl...  5739191.xml    1      1   \n",
       "2  Welajati: Iran bleibt bei einem Krieg am Golf ...  5739193.xml    1      1   \n",
       "3  Bush will offenbar seinen Außenminister erneut...  5739195.xml    1      1   \n",
       "4  Morgenzusammenfassung Neue Runde diplomatische...  5739199.xml    1      1   \n",
       "\n",
       "   year rubrics source             keywords  \\\n",
       "0  1991      pl    dpa  Schalck-Golodkowski   \n",
       "1  1991      pl    dpa               Tschad   \n",
       "2  1991      pl    dpa       Golfkrise Iran   \n",
       "3  1991      pl    dpa        Golfkrise USA   \n",
       "4  1991      pl    dpa            Golfkrise   \n",
       "\n",
       "                                               title                  city  \\\n",
       "0  Schalck: Milliardenkredit sicherte Zahlungsfäh...                Berlin   \n",
       "1  Tschads Regierung: Bevölkerung soll Waffen abl...             N'Djamena   \n",
       "2  Welajati: Iran bleibt bei einem Krieg am Golf ...               Teheran   \n",
       "3  Bush will offenbar seinen Außenminister erneut...            Washington   \n",
       "4  Morgenzusammenfassung Neue Runde diplomatische...  Washington/Luxemburg   \n",
       "\n",
       "  genre wordcount topic                                         paragraphs  \n",
       "0             218  WiPo  [Berlin (dpa) - Nach Darstellung des früheren ...  \n",
       "1              75  WiPo  [N'Djamena (dpa) - Die tschadische Regierung h...  \n",
       "2              90  WiPo  [Teheran (dpa) - Iran wird im Falle eines Krie...  \n",
       "3             181  WiPo  [Washington (dpa) - US-Präsident George Bush w...  \n",
       "4             504  WiPo  [Washington/Luxemburg (dpa) - Zwei Wochen vor ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove short articles (<100 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short articles are often incoherent or contain only insiginicant news. For this reason we decided to filter out articles that consist of less than 100 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:03:42.137776\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    count_results = pool.map(count_words_mp.count_words_mp, [text.replace('PARAGRAPH', ' ') for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result as a new column \"word_count\"\n",
    "data['word_count'] = count_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5364634\n"
     ]
    }
   ],
   "source": [
    "# remove articles with less than 100 words\n",
    "data = data[data['word_count']>=100]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove exact duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few examples of duplicates in our corpus:\n",
    "* The same article enters the corpus twice with different publication dates (e.g., 10.1.1991 and 11.1.1991). In this case, a natural solution is to keep the first entry.\n",
    "* The same article appears twice with a slight variation in the metadata (e.g., the word count is a little different even though the articles are identical, or the keywords differ).\n",
    "* The same article enters the corpus twice with the same publication date and metadata.\n",
    "* The same article is published by dpa and dpa-afx (in this case, we keep an article published by dpa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['year', 'month', 'day', 'topic'], ascending=[True, True, True, True]) # dpa articles come before afx articles\n",
    "data.reset_index(inplace=True, drop=True) # reset the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1595777"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the duplicated articles are saved as 'dpa_duplicates' for further exploration.\n",
    "dpa_duplicates = data[data['texts'].duplicated(keep = False)]\n",
    "len(dpa_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>file</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>source</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>genre</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>topic</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Neues Schema für Investmentkurse Achtung: Vom ...</td>\n",
       "      <td>5739254.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa</td>\n",
       "      <td>KURSE DREI A)</td>\n",
       "      <td>Neues Schema für Investmentkurse Achtung: Vom ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>544</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Die folgenden Positionen der bisherigen Tabel...</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NEUES INVESTMENTSCHEMA. 125) FF RESERVE FONDS ...</td>\n",
       "      <td>5739268.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa</td>\n",
       "      <td>KURSE DREI B</td>\n",
       "      <td>NEUES INVESTMENTSCHEMA.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>489</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[125) FF RESERVE FONDS          126) FMM-FONDS...</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NEUES INVESTMENTSCHEMA. 247) RE-INRENTA 248) R...</td>\n",
       "      <td>5739273.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa</td>\n",
       "      <td>KURSE DREI C)</td>\n",
       "      <td>NEUES INVESTMENTSCHEMA.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>430</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[247) RE-INRENTA                248) RENDITDEK...</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Neues Schema für Investmentkurse Achtung: Vom ...</td>\n",
       "      <td>5740026.xml</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa</td>\n",
       "      <td>KURSE DREI A)</td>\n",
       "      <td>Neues Schema für Investmentkurse Achtung: Vom ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>544</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[Die folgenden Positionen der bisherigen Tabel...</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>NEUES INVESTMENTSCHEMA. 125) FF RESERVE FONDS ...</td>\n",
       "      <td>5740028.xml</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa</td>\n",
       "      <td>KURSE DREI B</td>\n",
       "      <td>NEUES INVESTMENTSCHEMA.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>489</td>\n",
       "      <td>WiPo</td>\n",
       "      <td>[125) FF RESERVE FONDS          126) FMM-FONDS...</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts         file  day  \\\n",
       "13   Neues Schema für Investmentkurse Achtung: Vom ...  5739254.xml    1   \n",
       "15   NEUES INVESTMENTSCHEMA. 125) FF RESERVE FONDS ...  5739268.xml    1   \n",
       "16   NEUES INVESTMENTSCHEMA. 247) RE-INRENTA 248) R...  5739273.xml    1   \n",
       "209  Neues Schema für Investmentkurse Achtung: Vom ...  5740026.xml    2   \n",
       "210  NEUES INVESTMENTSCHEMA. 125) FF RESERVE FONDS ...  5740028.xml    2   \n",
       "\n",
       "     month  year rubrics source       keywords  \\\n",
       "13       1  1991      wi    dpa  KURSE DREI A)   \n",
       "15       1  1991      wi    dpa   KURSE DREI B   \n",
       "16       1  1991      wi    dpa  KURSE DREI C)   \n",
       "209      1  1991      wi    dpa  KURSE DREI A)   \n",
       "210      1  1991      wi    dpa   KURSE DREI B   \n",
       "\n",
       "                                                 title city genre wordcount  \\\n",
       "13   Neues Schema für Investmentkurse Achtung: Vom ...                  544   \n",
       "15                             NEUES INVESTMENTSCHEMA.                  489   \n",
       "16                             NEUES INVESTMENTSCHEMA.                  430   \n",
       "209  Neues Schema für Investmentkurse Achtung: Vom ...                  544   \n",
       "210                            NEUES INVESTMENTSCHEMA.                  489   \n",
       "\n",
       "    topic                                         paragraphs  word_count  \n",
       "13   WiPo  [Die folgenden Positionen der bisherigen Tabel...         283  \n",
       "15   WiPo  [125) FF RESERVE FONDS          126) FMM-FONDS...         258  \n",
       "16   WiPo  [247) RE-INRENTA                248) RENDITDEK...         262  \n",
       "209  WiPo  [Die folgenden Positionen der bisherigen Tabel...         283  \n",
       "210  WiPo  [125) FF RESERVE FONDS          126) FMM-FONDS...         258  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa_duplicates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some articles are more than once in the corpus. We filter out all duplicates and only keep the articles with the oldest date or the articles published by dpa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4542316\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(['texts'], keep = 'first', inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrections and updates of text news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of articles that we consider separately: text news corrections and updates.\n",
    "\n",
    "* In text news corrections (Berichtigung or Berichtigte Neufassung), journalists usually change only a few facts. More rarely, they add or rewrite several paragraphs. In most of the cases, corrected and original news texts are pubished on the same day.\n",
    "\n",
    "* In the updated texts news (Aktualisierung), journalists add a small amount of text to reflect the latest status. These articles can be published a few days later than the original article. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrected news texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corrected news texts do not contain much new information, so we treat them as duplicates. However, before deleting these articles, we check if we can always find the original articles in the dataset.\n",
    "\n",
    "Often the titles of corrected news articles include the titles of the original articles. For example, the title of the corrected article 'Berichtigung: Zahl der betroffenen US-Staaten Clinton will 23,5 Millionen Hektar Nationalforst schützen.' includes information on what was changed (Berichtigung: Zahl der betroffenen US-Staaten) and the title of the original article 'Clinton will 23,5 Millionen Hektar Nationalforst schützen.'.\n",
    "\n",
    "We use this fact and try to find pairs of original and corrected news reports with the same title. While the titles of corrected news reports may have a different format, being able to find pairs of articles sharing the same title in each time period means that there are no temporal changes in the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corrected news reports contain 'Berichtigung' (correction) or 'Berichtigte Neufassung' (corrected version) in the title. However, we exclude the articles on rectified shares that include 'Berichtigungsaktien' in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected news reports in dpa data.\n",
    "Berichtigung = data[(data.title.str.contains('Berichtigung|Berichtigte Neufassung')) & (~data.title.str.contains('Berichtigungsaktien')) & (data.topic == 'WiPo')].drop(columns =['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:18:41.092515\n"
     ]
    }
   ],
   "source": [
    "# track time\n",
    "startTime = datetime.now()\n",
    "# List with a publication year of the corrected articles\n",
    "inputs_year = []\n",
    "# List with a publication month of the corrected articles\n",
    "inputs_month = []\n",
    "# List with a publication day of the corrected articles\n",
    "inputs_day = []\n",
    "# List with the titles of the corrected articles\n",
    "inputs_Berichtigung_title = []\n",
    "# List with the titles of all the articles published on the same day as the corrected article\n",
    "inputs_titles = []\n",
    "# In this project we will concentrate on dpa rather than dpa-afx data. Please see explanation below.\n",
    "dpa_data = data[data.topic=='WiPo']\n",
    "\n",
    "for ind in Berichtigung.index:\n",
    "    inputs_year.append(Berichtigung['year'][ind])\n",
    "    inputs_month.append(Berichtigung['month'][ind])\n",
    "    inputs_day.append(Berichtigung['day'][ind])\n",
    "    inputs_Berichtigung_title.append(Berichtigung['title'][ind])\n",
    "    inputs_titles.append(list(dpa_data[(dpa_data['year'] == Berichtigung['year'][ind]) & (dpa_data['month'] == Berichtigung['month'][ind]) & (dpa_data['day'] == Berichtigung['day'][ind])][\"title\"]))        \n",
    "inputs = list(zip(inputs_year, inputs_month, inputs_day, inputs_Berichtigung_title, inputs_titles))\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function `Berichtigung_pairs` to output the dataframe that contains the titles of the corrected and original articles along with their publication date. This dataframe will help us understand if there are some temporal changes in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:18.315837\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "import Berichtigung_pairs\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    Berichtigung_intermediate = pool.map(Berichtigung_pairs.Berichtigung_pairs, inputs)\n",
    "    Berichtigung_df = pd.concat(Berichtigung_intermediate) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this dataframe includes 16982 titles of the corrected and original articles, while the total number of corrected articles is equal to 34221."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pairs found = 16892\n",
      "The number of corrected articles = 34221\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title_Berichtigung</th>\n",
       "      <th>title_main</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Berichtigte Neufassung dpa 159 - DLW - Bietigh...</td>\n",
       "      <td>DLW legte 1990 zu - besonders Möbelbereich erf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Berichtigte Neufassung - Wiesbaden/1257 Preise...</td>\n",
       "      <td>Preise in den neuen Ländern bei starken Bewegu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1991</td>\n",
       "      <td>Berichtigte Neufassung amnesty - London/0107 )...</td>\n",
       "      <td>amnesty international setzt sich für US-Wehrdi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1991</td>\n",
       "      <td>Berichtigte Neufassung - Bundeshaushalt - Bonn...</td>\n",
       "      <td>Bundeshaushalt 1991 mit 400 Milliarden Mark fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1991</td>\n",
       "      <td>Berichtigte Neufassung - München/1321 Patentam...</td>\n",
       "      <td>Patentamt erwartet Schub durch ostdeutsche Erf...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  day  month  year                                 title_Berichtigung  \\\n",
       "0      0    7      1  1991  Berichtigte Neufassung dpa 159 - DLW - Bietigh...   \n",
       "1      0   22      1  1991  Berichtigte Neufassung - Wiesbaden/1257 Preise...   \n",
       "2      0    7      2  1991  Berichtigte Neufassung amnesty - London/0107 )...   \n",
       "3      0    7      2  1991  Berichtigte Neufassung - Bundeshaushalt - Bonn...   \n",
       "4      0    8      4  1991  Berichtigte Neufassung - München/1321 Patentam...   \n",
       "\n",
       "                                          title_main  \n",
       "0  DLW legte 1990 zu - besonders Möbelbereich erf...  \n",
       "1  Preise in den neuen Ländern bei starken Bewegu...  \n",
       "2  amnesty international setzt sich für US-Wehrdi...  \n",
       "3  Bundeshaushalt 1991 mit 400 Milliarden Mark fa...  \n",
       "4  Patentamt erwartet Schub durch ostdeutsche Erf...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Berichtigung_df = Berichtigung_df.reset_index()\n",
    "print(\"The number of pairs found = {}\".format(len(Berichtigung_df)))\n",
    "print(\"The number of corrected articles = {}\".format(len(Berichtigung)))\n",
    "Berichtigung_df['day'] = list(map(int, Berichtigung_df.day))\n",
    "Berichtigung_df['month'] = list(map(int, Berichtigung_df.month))\n",
    "Berichtigung_df['year'] = list(map(int, Berichtigung_df.year))\n",
    "Berichtigung_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand why this is the case, we create a dataframe with the number of corrected articles (column 'texts') and identified pairs (column 'title_Berichtigung') per year.\n",
    "\n",
    "We can see that before 1999, the number of corrected articles is low, which explains why the number of identified original articles is also low. Between 1999 and 2011, the number of corrected articles ranges between between 900 and 2000, and we successfully identify most of the original articles that have the same title as their corrections.\n",
    "\n",
    "However, from 2012 onwards, the number of original articles that we are able to find decreases significantly. After further exploration, we realised that over this period of time most of the original articles had been removed. Therefore, we decided to delete only those corrected articles that were published before 2012 to avoid the risk of getting rid of unique articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>texts</th>\n",
       "      <th>title_Berichtigung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>103</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>138</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>148</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>136</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>123</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>164</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>177</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>428</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999</td>\n",
       "      <td>1323</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>1245</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001</td>\n",
       "      <td>936</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002</td>\n",
       "      <td>1331</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>1503</td>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>1360</td>\n",
       "      <td>1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>1598</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>1585</td>\n",
       "      <td>1248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007</td>\n",
       "      <td>1784</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>2245</td>\n",
       "      <td>1729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009</td>\n",
       "      <td>2100</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010</td>\n",
       "      <td>2006</td>\n",
       "      <td>1590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011</td>\n",
       "      <td>1886</td>\n",
       "      <td>1269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>1868</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>1821</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014</td>\n",
       "      <td>1784</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>1707</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>1646</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>1520</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>1556</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  texts  title_Berichtigung\n",
       "0   1991    103                  16\n",
       "1   1992    138                  22\n",
       "2   1993    148                  20\n",
       "3   1994    136                  26\n",
       "4   1995    123                  36\n",
       "5   1996    164                  45\n",
       "6   1997    177                  56\n",
       "7   1998    428                 182\n",
       "8   1999   1323                 678\n",
       "9   2000   1245                 673\n",
       "10  2001    936                 561\n",
       "11  2002   1331                 974\n",
       "12  2003   1503                1100\n",
       "13  2004   1360                1001\n",
       "14  2005   1598                1214\n",
       "15  2006   1585                1248\n",
       "16  2007   1784                1357\n",
       "17  2008   2245                1729\n",
       "18  2009   2100                1599\n",
       "19  2010   2006                1590\n",
       "20  2011   1886                1269\n",
       "21  2012   1868                 102\n",
       "22  2013   1821                  98\n",
       "23  2014   1784                  98\n",
       "24  2015   1707                  64\n",
       "25  2016   1646                  45\n",
       "26  2017   1520                  43\n",
       "27  2018   1556                  37"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = Berichtigung.groupby('year').nunique()['texts'].to_frame().reset_index()\n",
    "df2 = Berichtigung_df.groupby('year').nunique()['title_Berichtigung'].to_frame().reset_index()\n",
    "merged_df = df1.merge(df2, how = 'left')\n",
    "merged_df['title_Berichtigung'] = merged_df['title_Berichtigung'].astype('Int64')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we delete the corrected articles published before 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4519997\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[(data['title'].str.contains('Berichtigung|Berichtigte Neufassung', na = False)) & (~data['title'].str.contains('Berichtigungsaktien', na=False)) & \\\n",
    "               (data.topic == 'WiPo') & (data.year < 2012)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updated news texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The updated news texts might contain relatively large chunks of new information. Therefore, we do not want to delete them. Instead, we have done the following:\n",
    "\n",
    "1. If we manage to find an updated news text and its original version and both are published on the same day, we delete the original article as it does not contain the latest information.\n",
    "\n",
    "2. If the update and the original article are published on different days, we keep both news reports. The original article is important because it was published on the day market participants received the news. At the same time, the updated artilce might contain important new information. If there are several updates, we only keep the latest one as containing the full information. In case the latest update is very close to the original article, it will be removed later by the `fuzzy_duplicates` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:07:27.091103\n"
     ]
    }
   ],
   "source": [
    "from aktualisierung import delete_aktualisierung_index\n",
    "# In this project we will concentrate on dpa rather than dpa-afx data. Please see explanation below.\n",
    "# We do not consider articles that contain 'Nachrichtenüberblick' in the keywords because these articles \n",
    "# contain multiple articles.\n",
    "dpa_data = data[(data.topic=='WiPo') & (~data.keywords.str.contains('Nachrichtenüberblick'))]\n",
    "dates = dpa_data.groupby(['year', 'month', 'day'])\n",
    "dates = list(dates.groups)\n",
    "dates = np.array_split(dates, NUM_CORE)\n",
    "chunks = [pd.concat([dpa_data[(dpa_data['year'] == t[0]) & (dpa_data['month'] == t[1]) & (dpa_data['day'] == t[2])] for t in tup]) for tup in dates]\n",
    "# Use the 'delete_aktualisierung_index' function to get a list with indices of all indermediate updates and \n",
    "# original articles published on the same day as the respective updates.\n",
    "startTime = datetime.now()\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    aktualisierung_index = pool.map(delete_aktualisierung_index, chunks)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "print(datetime.now()-startTime)\n",
    "aktualisierung_index = [idx for l in aktualisierung_index for idx in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4518993\n"
     ]
    }
   ],
   "source": [
    "# Delete indermediate updates and original articles published on the same day as the respective updates based on indices.\n",
    "data.drop(aktualisierung_index, inplace = True)\n",
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates specific to article types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exploring corrected and updated news texts, we realised that there are other types of articles that suffer from the problem of duplication. These are summaries (Zusammenfassung, Gesamtzusammenfassung, Morgenfassung), overviews (Überblick), repeated articles (Wiederholung), and advance notifications (Vorausmeldung).\n",
    "\n",
    "* __Summaries (Zusammenfassung, Gesamtzusammenfassung, Morgenfassung)__\n",
    "\n",
    "Often we may see two versions of the same (or almost the same) article on the same day: the first is the original article and the second is a summary of that article. Many summaries are actually similar to updated articles because they consist of the original article and a new piece of text. However, in some cases, the summary is a condensed version of the original article including only the most important information. In any case, the content of the summary and the original article are very similar or identical. Therefore, if we can identify an original article and a summary published on the same day and with the same title, we consider the shorter article as a duplicate. In our corpus, we have 49,773 duplicates of this type.\n",
    "\n",
    "* __Overviews (Überblick)__\n",
    "\n",
    "In most cases, overviews are stand-alone articles containing all the information about a particular event available on a particular day. Sometimes, however, journalists write an article about a certain event in the morning, and then publish an overview in the evening, which is an extended version of the original article describing the latest developments. These overivews are very similar to updated news texts. We find 4,675 overviews with the same title as the original articles and published on the same day. We remove the short article from the overview and the original article.\n",
    "\n",
    "* __Repeated articles (Wiederholung)__\n",
    "\n",
    "We found 1,482 repeated articles with the same title as the original articles and published on the same day. These articles are either identical to the original articles or contain a small correction ('Berichtigte Wiederholung'). We remove the short article from the repeated article and the original article.\n",
    "\n",
    "* __Advance notifications (Vorausmeldung)__\n",
    "\n",
    "Advance notifications are news articles about events that will take place in the future. We found 606 advance notifications that have the same title as other articles published on the same day. In these cases, the advance notifications are a shorter version of the original articles. If we can identify an original article and an advance notification published on the same day and with the same title, we consider the shorter article as a duplicate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the function `duplicates_pairs` to output the data frame with the titles of duplicates and original articles along with their publication day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select article types that potentially suffer from the duplication problem. These are summaries (Zusammenfassung, \n",
    "# Gesamtzusammenfassung, Morgenfassung), overviews (Überblick), repeated articles (Wiederholung), and advance notifications\n",
    "# (Vorausmeldung).\n",
    "\n",
    "# In this project we will concentrate on dpa rather than dpa-afx data. Please see explanation below.\n",
    "\n",
    "# We do not consider articles that contain 'dpa-Vorausmeldungen kompakt' in the title or 'Nachrichtenüberblick' in the \n",
    "# keywords because these articles contain multiple articles.\n",
    "\n",
    "dup_types = data[(data.title.str.contains('Zusammenfassung|zusammenfassung|Überblick|Wiederholung|Vorausmeldung')) & (data.topic == 'WiPo') & \\\n",
    "                 (~data.title.str.contains('dpa-Vorausmeldungen kompakt')) & (~data.keywords.str.contains('Nachrichtenüberblick'))]\n",
    "len(dup_types)\n",
    "\n",
    "# Dates on which at least one summary, overview, repeated article, or advance notification is published.\n",
    "dates = dup_types.groupby(['year', 'month', 'day'])\n",
    "dates = list(dates.groups)\n",
    "# Exclude dpa-afx data and articles that contain 'Nachrichtenüberblick' in the keywords.\n",
    "dpa_data = data[(data.topic=='WiPo') & (~data.keywords.str.contains('Nachrichtenüberblick'))]\n",
    "# Create a list of data frames, where each data frame contains all the articles published on the same day as one of \n",
    "# the summaries, overviews, repeated articles, or advance notifications.\n",
    "day_df = [dpa_data[(dpa_data['year'] == t[0]) & (dpa_data['month'] == t[1]) & (dpa_data['day'] == t[2])] for t in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:03:49.153319\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "# Use the function duplicate_pairs to return the dataframe with the titles of duplicates and original articles \n",
    "# along with their publication date.\n",
    "import duplicates_pairs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    duplicates_intermediate = pool.map(duplicates_pairs.duplicates_pairs, day_df)\n",
    "    duplicates_df = pd.concat(duplicates_intermediate) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of 705,975 summaries, overviews, repeated articles, and advance notifications, we find 56,535 articles that we consider to be duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pairs found = 56536\n",
      "The number of summaries, overviews, repeated articles, or advance notifications = 705975\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>title_duplicate</th>\n",
       "      <th>title_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Zusammenfassung Ernst von Siemens gestorben.</td>\n",
       "      <td>Ernst von Siemens gestorben.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Zusammenfassung Drei Polizisten in Bologna ers...</td>\n",
       "      <td>Drei Polizisten in Bologna erschossen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Morgenzusammenfassung Baker und Asis in Genf -...</td>\n",
       "      <td>Bush fordert vom Kongreß Zustimmung zu Militär...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Vorausmeldung Gesamtberliner Parlament konnsti...</td>\n",
       "      <td>Gesamtberliner Parlament konnstituiert sich.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>Zweite Zusammenfassung Gorbatschow rechtfertig...</td>\n",
       "      <td>Gorbatschow rechtfertigt Armee-Einsatz in Lita...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  day  month  year                                    title_duplicate  \\\n",
       "0      0    2      1  1991       Zusammenfassung Ernst von Siemens gestorben.   \n",
       "1      0    5      1  1991  Zusammenfassung Drei Polizisten in Bologna ers...   \n",
       "2      0    9      1  1991  Morgenzusammenfassung Baker und Asis in Genf -...   \n",
       "3      0   10      1  1991  Vorausmeldung Gesamtberliner Parlament konnsti...   \n",
       "4      0   14      1  1991  Zweite Zusammenfassung Gorbatschow rechtfertig...   \n",
       "\n",
       "                                      title_original  \n",
       "0                       Ernst von Siemens gestorben.  \n",
       "1             Drei Polizisten in Bologna erschossen.  \n",
       "2  Bush fordert vom Kongreß Zustimmung zu Militär...  \n",
       "3       Gesamtberliner Parlament konnstituiert sich.  \n",
       "4  Gorbatschow rechtfertigt Armee-Einsatz in Lita...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates_df = duplicates_df.reset_index()\n",
    "print(\"The number of pairs found = {}\".format(len(duplicates_df)))\n",
    "print(\"The number of summaries, overviews, repeated articles, or advance notifications = {}\".format(len(dup_types)))\n",
    "duplicates_df['day'] = list(map(int, duplicates_df.day))\n",
    "duplicates_df['month'] = list(map(int, duplicates_df.month))\n",
    "duplicates_df['year'] = list(map(int, duplicates_df.year))\n",
    "duplicates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the function `delete_duplicates` to output indices of the duplicate articles. We then delete the articles with these indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:03:48.450534\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "# Use the function delete_duplicates to output indices of the duplicate articles.\n",
    "import delete_duplicates\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    duplicates_index = pool.map(delete_duplicates.delete_duplicates, day_df)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)\n",
    "duplicates_index = [idx for l in duplicates_index for idx in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4461990\n"
     ]
    }
   ],
   "source": [
    "# Delete duplicate articles.\n",
    "data.drop(duplicates_index, inplace = True)\n",
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, dpa articles are not as consistently sorted into sections and subsections as articles from other \n",
    "news media. Instead, we investigate the most commonly used titles and keywords and remove irrelevant articles based on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude irrelevant articles based on the following titles\n",
    "\n",
    "* 1) Londoner Edelmetallpreise: Precious metal prices (without text)\n",
    "* 2) Tageskalender: List of upcoming events\n",
    "* 3) (Tabelle), TABELLE: : Tables in text form\n",
    "* 4) SPORT, Sport (except for the titles that contain TRANSPORT, INTERSPORT, PASSPORT, Sportartikel, news about sportswear manufacturers, sporting goods industry, SPORTARTIKLER, Sportmodelle, or Sportswear): news related to Sports. Beware that news about sports marketing agencies (e.g., Sportfive), sports media websites (e.g., Sportal), and new sports models of car manufacturers might be removed as well. \n",
    "* 5) KORREKTUR: Article corrections\n",
    "* 6) Impressum: Dpa contact data\n",
    "* 7) Testmeldung: Test-articles from dpa\n",
    "* 8) Kurse A, Kurse B, Kurse C, Kurse D, KURSE A, KURSE B, KURSE C, KURSE DREI, KURSE Drei, Kurse drei: Stock charts without text\n",
    "* 9) DGAP-DD: DGAP reports\n",
    "* 10) New Yorker Aktien-Schlußkurse: Stock closing prices at the New York stock exchange (articles only occur from 1997 to 2002)\n",
    "* 11) VERMISCHTES: Miscellaneous with no relation to economics\n",
    "* 12) Angekündigte US-Quartalszahlen auf einen Blick: Quarterly US figures\n",
    "* 13) Terminvorschau: Appointment preview\n",
    "* 14) Aus der Landespolitik: News reports on regional politics. We think they are unlikely to be important for our research question. \n",
    "* 15) Die Woche in Berlin, Die Woche in Bonn, Die politische Woche: Announcements of political (and economic) news for next week. The format is very different from other news reports and difficult for the models we use.\n",
    "* 16) Notizen aus der Politik, NOTIZEN AUS DER POLITIK: Collection of varios short political articles which contentwise  do not seem to be relevant for our research question and are covered only within the limited time period, 2002-2011.\n",
    "* 17) Presseschau (except for the titles that contain 'zu'): Press reviews that include only headlines of important news reports from various media outlets. We can not analyze the full texts and headlines together because different types of data require different models. Articles with headlines containing both 'Presseschau' and 'zu' are actual press reviews (not just headlines) of a single newspaper on a single topic.\n",
    "* 18) ÜBERBLICK: Analysten-Umstufungen: Changes in stock ratings (different article format).\n",
    "* 19) Chronologie, CHRONOLOGIE: Chronology - important dates and events. We remove these articles because for our research question backward-looking articles are arguably not that important.\n",
    "* 20) dpa-Landesdienst: Regional news unlikely to be important for our research question.\n",
    "* 21) Die Top-Themen am Aktienmarkt: Short news articles about stock market. They do contain relevant information, but they also have a very different format and they were first issued in 2011. \n",
    "* 22) Aktien Asien Schluss.: Quantitative information about the stock market.\n",
    "* 23) Börsentag auf einen Blick: Articles about the stock market, different format, a lot of quantitative information.\n",
    "* 24) US-Quartalszahlen vom Vortag: Quarterly stock market figures, tables.\n",
    "* 25) Achtung - Sonderdisposition: A schedule of the upcoming news articles on a particular topic.\n",
    "* 26) dpa-Vorausmeldungen kompakt: Multiple short news articles on the upcoming events. The length of each of the articles usually does not exceed 100 words.\n",
    "* 27) Aktien-Schlußkurse: Stock market prices, quantitative information.\n",
    "* 28) Tabelle Kurse: Stock market figures, tables.\n",
    "* 29) Tabelle Die Gewinner und Verlierer: Stock market figures, tables.\n",
    "* 30) Auf und ab im EWS: changes in exchange rates due to introduction of European Monerary System, quantitative information.\n",
    "* 31) Der Verfassungsschutzbericht in Zahlen: crime statistics, quantitative information.\n",
    "* 32) Die Toten des Jahres: list of celebrity deaths this year.\n",
    "* 33) Spendenkonten für Jugoslawien-Hilfe: list of donation accounts for Yugoslavia aid.\n",
    "* 34) Kontonummern für die Ruanda-Hilfe: list of donation accounts for Rwanda aid.\n",
    "* 35) Extra Zahlreiche Hilfsorganisationen: list of donation accounts for Kosovo victims.\n",
    "* 36) dpa-Schwerpunkt Spendenkonten: list of donation accounts for East Africa aid.\n",
    "* 37) Tabelle Weltbörsen und Finanzmärkte auf einen Blick: quantitative information on stock market.\n",
    "* 38) Interbanken-Kurse und Metallnotierungen: quantitative news articles on interbank exchange rates and metal prices.\n",
    "* 39) Hintergrund: background articles are not news in themselves, but rather they provide background information on the topic. These articles are often outdated or irrelevant for short-term economic analysis. They might also contain a high share of quantitative information (e.g., detailed labour market statistics, election results in numbers).\n",
    "* 40) Chronik eins/zwei/drei/vier/fünf/sechs/sieben/acht/neun/zehn/elf/zwölf: backward-looking articles.\n",
    "* 41) Liste eins/zwei/drei/vier/fünf, Subventionsliste eins/zwei: long lists with a lot of background information on the topic, e.g. lists of members of the 16th Bundestag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4028344\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-economic articles based on titles.\n",
    "fil_titles = '''Londoner Edelmetallpreise|Tageskalender|\\(Tabelle\\)|SPORT|Sport|KORREKTUR|Impressum|Testmeldung|Kurse A[^a-z]|Kurse B[^a-z]|Kurse C[^a-z]|Kurse D[^a-z]|KURSE A|KURSE B|KURSE C|KURSE DREI|Kurse drei|KURSE Drei|Kurse/drei|DGAP-DD|New Yorker Aktien-Schlusskurse|VERMISCHTES|Angekündigte US-Quartalszahlen|Terminvorschau|Aus der Landespolitik|Die Woche in Berlin|Die Woche in Bonn|Die politische Woche|Notizen aus der Politik|NOTIZEN AUS DER POLITIK|ÜBERBLICK: Analysten-Umstufungen|TABELLE:|Chronologie|CHRONOLOGIE|dpa-Landesdienst|Die Top-Themen am Aktienmarkt|Aktien Asien Schluss\\.|Börsentag auf einen Blick|US-Quartalszahlen vom Vortag|Achtung - Sonderdisposition|dpa-Vorausmeldungen kompakt|Aktien-Schlußkurse|Tabelle Kurse|Tabelle Die Gewinner und Verlierer|Auf und ab im EWS|Der Verfassungsschutzbericht in Zahlen|Die Toten des Jahres|Spendenkonten für Jugoslawien-Hilfe|Kontonummern für die Ruanda-Hilfe|Extra Zahlreiche Hilfsorganisationen|dpa-Schwerpunkt Spendenkonten|Tabelle Weltbörsen und Finanzmärkte auf einen Blick|Interbanken-Kurse und Metallnotierungen|Hintergrund|Chronik eins|Chronik zwei|Chronik drei|Chronik vier|Chronik fünf|Chronik sechs|Chronik sieben|Chronik acht|Chronik neun|Chronik zehn|Chronik elf|Chronik zwölf|Liste eins|Liste zwei|Liste drei|Liste vier|Liste fünf|Subventionsliste eins|Subventionsliste zwei'''\n",
    "titles_exc = '''TRANSPORT|INTERSPORT|PASSPORT|Sportartikel|SPORTARTIKLER|Sportmodelle|Sportswear'''\n",
    "data.drop(data[(data['title'].str.contains(fil_titles, na = False)) & (~data['title'].str.contains(titles_exc, na=False))].index, inplace=True)\n",
    "# Filter out press reviews that consist of headlines only\n",
    "data.drop(data[(data['title'].str.contains('Presseschau', na = False)) & (~data['title'].str.contains('zu', na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude articles based on a title and a text:\n",
    "\n",
    "* 1) A title contains 'Überblick: ANALYSTEN-EINSTUFUNGEN', and a text contains 'Folgende Investmentbanken haben sich': Changes in stock ratings (different article format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4025351\n"
     ]
    }
   ],
   "source": [
    "# Filter out articles based on a title and a text.\n",
    "data.drop(data[(data.title.str.contains('Überblick: ANALYSTEN-EINSTUFUNGEN', na = False)) & (data.texts.str.contains('Folgende Investmentbanken haben sich', na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2) A title is 'Achtung.', and a text contains 'Zusammenfassung': A schedule of the upcoming news articles on a particular topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4025325\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[(data.title =='Achtung.') & (data.texts.str.contains('Zusammenfassung', na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude articles based on a title and keywords:\n",
    "\n",
    "* 1) A title contains 'Dispositionen', and keywords contain 'Wahl' or 'wahl': quantitative information about elections (different article format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4024900\n"
     ]
    }
   ],
   "source": [
    "# Filter out articles based on a title and keywords.\n",
    "data.drop(data[(data.title.str.contains('Dispositionen', na = False)) & (data.keywords.str.contains('Wahl|wahl', na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 2) A title contains 'Achtung', and keywords consist of one word 'Kurse': quantitative information about prices (different article format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4024889\n"
     ]
    }
   ],
   "source": [
    "# Filter out articles based on a title and keywords.\n",
    "data.drop(data[(data.title.str.contains('Achtung', na = False)) & (data.keywords == 'Kurse')].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3) A title consists of one word 'Achtung.', and keywords contain 'Börsen': internal information about changes in reporting (different article format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4024865\n"
     ]
    }
   ],
   "source": [
    "# Filter out articles based on a title and keywords.\n",
    "data.drop(data[(data.title == 'Achtung.') & (data.keywords.str.contains('Börsen', na = False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude irrelevant articles based on the following sections.\n",
    "\n",
    "* 1) Tabelle: Tables in text form (some articles are still left after the previos step)\n",
    "* 2) Historisches: News about historical events\n",
    "* 3) Achtung: Announcemt of upcoming news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4004947\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-economic articles based on sections.\n",
    "fil_genres = '''Tabelle|Historisches|Achtung'''\n",
    "data.drop(data[data['genre'].str.contains(fil_genres, na = False)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude non-economic articles based on the following keywords.\n",
    "* 1) Redaktionshinweis: Editor's notes for Dpa journalists\n",
    "* 2) DGAP: DGAP reports\n",
    "* 3) Sport, SPORT, SPO (except for Sportartikel, this section contains articles on sports companies): Sport news (some sports articles are still left after the previos steps)\n",
    "* 4) Kurse A, Kurse B, Kurse C, Kurse D, KURSE A, KURSE B, KURSE C, Kurse D,\n",
    "     KURSE DREI, Kurse drei, KURSE Drei, KURSE drei, Kurse Drei, Kurse/drei: Stock charts without text (some articles are  still left after the previos steps)\n",
    "* 5) Tagesvorschau, Vorschau, VORSCHAU, vorschau: List of titles of upcoming news\n",
    "* 6) Bilderdienst: Dpa Picture Service\n",
    "* 7) Geschichte: News related to historical events\n",
    "* 8) Landespolitik: Regional news irrelevant for economic forecasting\n",
    "* 9) dpa-Morgenlage: News about what happened last night. These articles have a special format: quick and very short reports.\n",
    "* 10) Börsen Aktienkurse Währung: Quantitative information about stock market\n",
    "* 11) Rechtschreibung: News about German Orthography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3764930\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-economic articles based on keywords.\n",
    "fil_keywords = '''Redaktionshinweis|DGAP|Sport|SPORT|SPO|Kurse A|Kurse B|Kurse C|Kurse D|KURSE A|KURSE B|KURSE C|KURSE DREI|Kurse drei|KURSE Drei|KURSE drei|Kurse Drei|Kurse/drei|Kurse D|Tagesvorschau|Vorschau|vorschau|VORSCHAU|Bilderdienst|Geschichte|Landespolitik|dpa-Morgenlage|Börsen Aktienkurse Währung|Rechtschreibung'''\n",
    "keywords_exc = '''Sportartikel'''\n",
    "data.drop(data[(data['keywords'].str.contains(fil_keywords, na = False)) & (~data['keywords'].str.contains(keywords_exc, na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude articles based on keywords and text:\n",
    "\n",
    "* 1) Keywords contain 'Wahlen', and a text contains 'Abkürzungen:': quantitative information about elections (different article format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3764737\n"
     ]
    }
   ],
   "source": [
    "# Filter out articles based on keywords and text.\n",
    "data.drop(data[(data.keywords.str.contains('Wahlen', na = False)) & (data.texts.str.contains('Abkürzungen\\:', na = False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude articles based on the following bits of text.\n",
    "* 1) Schalterverkaufskurse: Precios metal prices\n",
    "* 2) dpa-news.de: News regarding the Dpa website\n",
    "* 3) Wirtschafts- und Finanztermine, Wirtschafts- und Finanz-Termine, Konjunktur- und Wirtschaftstermine: List of dates when economic data will be published/economic events will take place\n",
    "* 4) DGAP (except for articles that contain DGAP standing for Deutsche Gesellschaft für Auswärtige Politik): DGAP reports\n",
    "* 5) Bitte verwenden Sie diese Meldung nicht: Retracted articles\n",
    "* 6) [§] 26 Abs., § 15a WpHG 1, § 15 WpHG, Artikel 19 MAR, article 19 Market Abuse Regulation (MAR): Regulatory news\n",
    "* 7) Die Pivotpunkte für den Dax-Future: Pivot points for the Dax-Future\n",
    "* 8) An der Frankfurter Wertpapierbörse wurden, Die Aktien im Dow Jones EuroStoxx 50, Die Aktien im Dow Jones Euro Stoxx 50: Stock charts\n",
    "* 9) Ihr Ansprechpartner: Redaktion Politik International: List of current political news headlines\n",
    "* 10) (Achtung - Sonderdisposition): A schedule of the upcoming news articles on a particular topic\n",
    "* 11) Redaktionstechnik Augsburger Allgemeine: most of the article contains contact information for Augsburger Allgemeine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633513\n"
     ]
    }
   ],
   "source": [
    "fill_text = '''Schalterverkaufskurse:|dpa-news\\.de|Wirtschafts- und Finanztermine|Wirtschafts- und Finanz-Termine|DGAP|Bitte verwenden Sie diese Meldung nicht|Konjunktur- und Wirtschaftstermine|[§] 26 Abs\\. 1|§ 15a WpHG|§ 15 WpHG|Artikel 19 MAR|article 19 Market Abuse Regulation \\(MAR\\)|Die Pivotpunkte für den Dax-Future|An der Frankfurter Wertpapierbörse wurden|Die Aktien im Dow Jones EuroStoxx 50|Die Aktien im Dow Jones Euro Stoxx 50|\\(Achtung - Sonderdisposition\\)|Redaktionstechnik Augsburger Allgemeine'''\n",
    "text_exc = '''Auswärtige Politik'''\n",
    "data.drop(data[(data['texts'].str.contains(fill_text, na = False)) & (~data['texts'].str.contains(text_exc, na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we exclude articles containing both 'Ihr Ansprechpartner\\:' and '\\(.+[0-9] Zl\\)' in the text. They include a schedule of the upcoming news articles on a particular topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633285\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[(data['texts'].str.contains('Ihr Ansprechpartner\\:', na = False)) & (data['texts'].str.contains('\\(.+[0-9] Zl\\)', na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to exclude irrelevant articles based on the following two sources.\n",
    "* 1) dpa-frei: Article corrections\n",
    "* 2) dpa-wahl: Articles about federal election results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633261\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[data['source'].str.contains('dpa-frei|dpa-wahl', na = False)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude articles regarding dpa itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633258\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[data['city'] == 'Die Deutsche Presse-Agentur'].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep articles on two subjects: Politics ('wi') and Economy ('wi'). Articles with the 'rs' value of the column 'rubrics' are removed, because 'rs' stands for editorial management. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632165\n"
     ]
    }
   ],
   "source": [
    "data = data[(data['rubrics']==u'wi') | (data['rubrics']==u'pl')]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove four articles published in 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3632161\n"
     ]
    }
   ],
   "source": [
    "data = data[data['year']<2019]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes multiple articles are collected and merged into one entry. For example, articles with the title, keyword, or genre \n",
    "'Nachrichtenüberblick' are a collection of the most important articles of the day. Because these smaller articles\n",
    "can have different sentiments and topics, we separate articles that consist of multiple smaller articles. Articles consisting of multiple smaller articles can be identified with the following words which can appear in titles, keywords, or genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dpa-Nachrichtenüberblick, Nachrichtenüberblick: An overview of news for the upcomming days or news which are a few days old\n",
    "- Kurznachrichten Wirtschaft: Collection of short economic news\n",
    "- Analysten-Einstufungen, ANALYSTEN-EINSTUFUNGEN: Analyst stock ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete one of the articles containing 'Nachrichtenüberblick' in the title because it has too many errors that make it difficult to split the article into paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' PARAGRAPH     Rentenreform verabschiedet\\n  PARAGRAPH     BERLIN - Der Weg für die Förderung der privaten Altersvorsorge\\nmit knapp 21 Mrd. DM ist frei.  e K\\n B h e i r t de. Auch das rot-rot-regierte Mecklenburg-Vorpommern\\nstimmte zu. Die SPD-CDU-Koalition von Bremen enthielt sich. In\\nMecklenburg-Vorpommern droht nach der überraschenden Zustimmung von\\nMinisterpräsident Ringstorff eine Koalitionskrise. Nach PDS-Ansicht\\nhat die SPD den Koalitionsvertrag gebrochen und damit den\\nRegierungspartner herausgefordert.\\n  PARAGRAPH    Mieter erhalten mehr Rechte\\n  PARAGRAPH    BERLIN - Die mehr als 20 Mio. Mieter in Deutschland erhalten von\\nSeptember an mehr Rechte. Die Grenze für Mieterhöhungen wird gesenkt\\nund die Kündigungsfristen werden zu Gunsten der Mieter geändert. Das\\nsieht die Mietrechtsreform der Bundesregierung vor, die am Freitag im\\nBundesrat die letzte parlamentarische Hürde nahm. Bisher betrugen die\\nKündigungsfristen für Mieter un d Vermieter gleichermaßen maximal\\nzwölf Monate. Im Interesse beruflicher Mobilität, aber auch für den\\nFall d     i   u   b  Für den\\nVermieter beträgt sie künftig maximal neun Monate.\\n  PARAGRAPH    Vertreter von NS-Zwangsarbeitern hoffen auf schnelle\\nEntschädigung\\n  PARAGRAPH    WARSCHAU/PRAG/MOSKAU - Nach der Zurückweisung der letzten\\nSammelklage in den USA hoffen Opfervertreter und Politiker in Mittel-\\nund Osteuropa auf eine möglichst schnelle Entschädigung der\\nehemaligen NS-Zwangsarbeiter. Auf die Auszahlung der 10 Mrd. DM aus\\ndem deutschen Entschädigungsfonds warten mehr als 1,5 Mio. NS-Opfer.\\nDavon leben eine Million auf dem Gebiet der ehemaligen Sowjetunion\\nund rund eine halbe Million in Polen. Vor der Auszahlung der Gelder\\nmuss der Bundestag noch formell feststellen, dass für die deutschen\\nUnternehmen Rechtssicherheit besteht.\\n  PARAGRAPH    Einheits-Regierung in Mazedonien immer noch fraglich\\n  PARAGRAPH    SKOPJE - Das Ringen um eine große Koalition der Volksgruppen in\\nMazedonien ist am Freitag weitergegangen.  a\\n n d n i e n sgruppe. Der mazedonische\\nMinisterpräsident Georgievski warnte die Albaner, dass das\\ninternational unterstützte Regierungsprojekt notfalls auch ohne ihre\\nPartei beginnen werde.\\n  PARAGRAPH    Nach Granaten-Angriff teilt Armee erneut Gazastreifen\\n  PARAGRAPH    GAZA/KAIRO - Mit einer Blockade mehrerer Straßen haben\\nisraelische Truppen heute den Gazastreifen praktisch geteilt und sind\\nerneut in autonomes Palästinensergebiet eingedrungen. Dabei\\nzerstörten Panzer und schwere Räumgeräte mehrere Gebäude der\\npalästinensischen Sicherheitskräfte. Zuvor hatten militante\\nPalästinenser Handgranaten auf zwei israelische Soldaten geworfen.\\n  PARAGRAPH    EU-Ausschuss wegen Abhörsystem von Amerikanern abgewiesen\\n  PARAGRAPH    WASHINGTON - Eine Delegation des Europäischen Parlaments, die\\nsich in den USA über das umstrittene Abhörsystem Echelon informierten\\nwollte, ist von der US-Regierung und dem amerikanischen Gehe I   u h\\n t l o ieben wird. Die\\nEuropaparlamentarier protestierten energisch gegen die kurzfristige\\nAbsage der abgesprochenen Treffen durch die Amerikaner./DP/ar\\n '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The article to delete\n",
    "file_drop = ['8180362.xml']\n",
    "ind = data[data.file == '8180362.xml']['texts'].index[0]\n",
    "data[data.file == '8180362.xml']['texts'][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data['file'].isin(file_drop)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While testing the code, we have decided to delete a quantitative part of the following two articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' PARAGRAPH     BERLIN(dpa-AFX) - Mit dem Bundeshaushalt 2004 und dem Finanzplan\\nbis 2007 bleibt die von der Bundesregierung geplante Neuverschuldung\\nvorerst im kritischen Bereich. Sie soll jetzt im kommenden Jahr 28,8\\nMilliarden Euro betragen, nachdem Finanzminister Hans Eichel (SPD)\\nund die Koalition übereingekommen sind, 2 Milliarden Erlöse aus dem\\nVerkauf weiterer Telekom- <DTE.ETR> und Postaktien <DPW.ETR> an die\\nKreditanstalt für Wiederaufbau zu erzielen. Diese soll das Paket\\nspäter bei guten Kursen an der Börse platzieren.\\nFür das laufende Jahr hat Eichel inzwischen eine Neuverschuldung\\nvon 35 Milliarden in den Haushaltsentwurf eingestellt, spricht aber\\nbereits von einer Verdoppelung der zunächst gesetzlich\\nverabschiedeten 18,9 Milliarden Euro. Dies wären etwa 38 Milliarden\\nneue Schulden. Die im Herbst erwartete Höhe soll dann in einen\\nNachtragshaushalt aufgenommen werden. Andere Fachleute der Koalition\\nsprechen schon von rund 40 Milliarden Euro. Die Opposition nennt\\nunter Berücksichtigung der höchst unsicheren Bundesratsentscheidungen\\nüber einzelne Sparvorhaben Eichels sogar eine Neuverschuldung bis 50\\nMilliarden Euro.\\nDie weitere Haushaltsentwicklung hängt wesentlich vom Gelingen der\\nReformen und den Steuereinnahmen ab. Bis 2007 möchte Eichel die neuen\\nSchulden auf 10 Milliarden herunterfahren. Hier die Eckwerte des\\nFinanzplans bis 2007:\\n\\nIstSollVollzugEntwurfFinanzplan\\n2002200320032004200520062007\\n=====================================================================\\nAusgaben249,3248,2257251,2251,2251,2254,9\\nSteuereinnahmen192,0203,3196201,4211,8221,4229,9\\nsonstige Einnahmen25,426,02620,918,414,815,0\\nNettokreditaufnahme 31,918,935  28,821,015,010,0\\nInvestitionen24,126,726,724,824,724,724,7\\n° /wb/DP/aa\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = data[data.file == '8833807.xml']['texts'].index[0]\n",
    "data[data.file == '8833807.xml']['texts'][ind1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' PARAGRAPH     BERLIN (dpa-AFX) - Der Entwurf des Bundeshaushalts 2004 sieht\\nAusgaben in Höhe von 251,2 Milliarden Euro vor. Das sind 1,2 Prozent\\nmehr als für das laufende Jahr gesetzlich geplant, aber 2,3 Prozent\\nweniger als das Finanzministerium jetzt für 2003 mit 257 Milliarden\\nEuro erwartet. Die neuen Schulden sind mit 28,8 Milliarden Euro\\neingeplant.\\nDas größte Ausgabevolumen verwaltet das Ressort für Gesundheit und\\nSoziales. Die hohe Steigerungsrate im Arbeits- und Wirtschaftsetat\\nvon Minister Wolfgang Clement (SPD) wird durch den hohen Zuschuss an\\ndie Bundesanstalt für Arbeit von 5,2 Milliarden Euro bestimmt.\\n\\nDie Übersicht über die Einzelpläne:\\nSollEntwurfVeränderung\\n20032004zum Vorjahr\\n(in Millionen Euro)(Prozent)\\n--------------------------------------\\nBundespräsidialamt20,4722,96+ 12,2\\nBundestag540,73548,93+1,5\\nBundesrat17,0617,80+4,3\\nBundeskanzleramt1.483,561.488,06+0,3\\nAuswärtiges Amt2.229,912.183,40-2,1\\nInnen4.014,004.092,58+2,0\\nJustiz345,35344,27-0,3\\nFinanzen3.286,623.338,03+1,6\\nWirtschaft und Arbeit18.508,1925.003,35+ 35,0\\nVerbraucherschutz und Agrar5.627,195.209,10-7,4\\nVerkehr, Bau und Wohnungswesen26.069,1026.491,84+1,6\\nVerteidigung24.378,7824.248,81-0,5\\nGesundheit und Soziales82.033,3181.882,49-0,2\\nUmwelt und Reaktorsicherheit794,02791,41-0,3\\nFamilie, Senioren, Jugend5.101,394.746,13-7,0\\nBundesverfassungsgericht16,2117,27+6,6\\nBundesrechnungshof75,2390,26+ 20,0\\nWirtschaftliche Zusammenarbeit3.767,543.800,00+0,9\\nBildung und Forschung8.364,228.209,19-1,8\\nBundesschuld39.940,1539.935,24+/- 0\\nVersorgung8.806,028.981,01+2,0\\nAllgemeine Finanzverwaltung12.779,989.757,86- 23,6\\n-------------------------------------\\ninsgesamt248.199,00251.200,00+1,2\\n=====================================°\\n/wb/DP/aa\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2 = data[data.file == '8833809.xml']['texts'].index[0]\n",
    "data[data.file == '8833809.xml']['texts'][ind2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.at[ind1, 'texts'] = data['texts'][ind1].split(' Hier die Eckwerte')[0]\n",
    "data.at[ind2, 'texts'] = data['texts'][ind2].split('\\n\\nDie Übersicht')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mokuneva\\AppData\\Local\\Temp\\2\\ipykernel_14376\\2680592192.py:3: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mult_art = mult_art.append(data[data['keywords'].str.contains(s_mult_art, na = False)])\n",
      "C:\\Users\\mokuneva\\AppData\\Local\\Temp\\2\\ipykernel_14376\\2680592192.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mult_art = mult_art.append(data[data['genre'].str.contains(s_mult_art, na = False)])\n"
     ]
    }
   ],
   "source": [
    "s_mult_art = '''dpa-Nachrichtenüberblick|Nachrichtenüberblick|Kurznachrichten Wirtschaft|Analysten-Einstufungen|ANALYSTEN-EINSTUFUNGEN'''\n",
    "mult_art = data[data['title'].str.contains(s_mult_art, na = False)]\n",
    "mult_art = mult_art.append(data[data['keywords'].str.contains(s_mult_art, na = False)])\n",
    "mult_art = mult_art.append(data[data['genre'].str.contains(s_mult_art, na = False)])\n",
    "mult_art.drop_duplicates(['texts'], keep = 'first', inplace=True)\n",
    "mult_art.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete 'mult_art' from the original data\n",
    "data.drop(data[data['title'].str.contains(s_mult_art, na = False)].index, inplace=True)\n",
    "data.drop(data[data['keywords'].str.contains(s_mult_art, na = False)].index, inplace=True)\n",
    "data.drop(data[data['genre'].str.contains(s_mult_art, na = False)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate chunck size \n",
    "chunk_size = int(mult_art.shape[0]/NUM_CORE)\n",
    "\n",
    "# split data into chunks \n",
    "chunks = [mult_art.iloc[mult_art.index[i:i + chunk_size]] for \n",
    "          i in range(0, mult_art.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:45.814573\n",
      "899420\n"
     ]
    }
   ],
   "source": [
    "# split up articles into smaller articles and append the resulting new articles \n",
    "# to the corpus\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    results = pool.map(split_articles.split_articles, chunks) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)\n",
    "\n",
    "results = pd.concat(results)\n",
    "print(len(results))\n",
    "results.reset_index(inplace=True, drop=True) # reset the index of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The separated articles consist of fewer words than the articles from which they originally stemmed. Therefore, we count the number of words of the new articles with the count_words_mp function from before and filter out articles with less than 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:08.202487\n"
     ]
    }
   ],
   "source": [
    "# count the number of words for the separated articles and filter out articles with less\n",
    "# than 100 words\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    count_results = pool.map(count_words_mp.count_words_mp, [text for text in results['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['word_count'] = count_results\n",
    "results = results[results['word_count']>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mokuneva\\AppData\\Local\\Temp\\2\\ipykernel_14376\\1601353168.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(results)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3615409\n"
     ]
    }
   ],
   "source": [
    "# append separated articles to corpus\n",
    "data = data.append(results)\n",
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True) # reset the index of the DataFrame\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dpa-Basisdienstes and dpa-afx Wirtschaftsnachrichten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we have been cleaning data from dpa-Basisdienstes (hereafter dpa) and dpa-afx Wirtschaftsnachrichten (hereafter afx) together. This made us realise that afx data has a completely different format and, while useful for forecasting, in our view should be analyzed separately from dpa data. Here we explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dpa news articles are very similar to the news we read in other newspapers, and they cover similar topics, namely major political and economic events.\n",
    "\n",
    "The afx news, on the other hand, is aimed at investors and traders rather than the general public, and closely follows stock market developments, companies' financial results, and the state of key industries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it clear what we mean, here are a few articles on topics that are frequently discussed in afx data.\n",
    "\n",
    "1. The first two articles discuss stock market developments.\n",
    "2. Articles three and four represent Ad hoc messages (information reported by companies that might influence the price of their securitites).\n",
    "3. Articles five and six give recommendations to traders whether they should sell, buy, or hold shares.\n",
    "4. The last two articles talk about financial results and plans of companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Articles on the stock market ----\n",
      "\n",
      "\n",
      "Aktien Neuer Markt: Kurse abgebröckelt - Etwas Erleichterung durch US -Daten. FRANKFURT (dpa-AFX) - Die deutschen Wachstumsaktien am Neuen Markt sind nach einer freundlichen Eröffnung stetig abgebröckelt. Im Vorfeld der mit Spannung erwarteten US-Konjunkturzahlen am Nachmittag (ab 14:30) wurden neue Tagestiefs markiert, bevor die Daten «in line» für etwas Erleichterung sorgten. Der Nemax-All-Share-Index <NMDK.ETR> lag zuletzt um 1,08% unter dem Vortagesniveau bei 3.231,70/-35,13 Punkten, während der Nemax50-Index <NMKX.ETR> 1,23% auf 4.068,60/-50,94 Punkte verlor. Vor den Zahlen saßen «alle wie das Kaninchen vor der Schlange und warteten», erklärte ein Händler aus Düsseldorf. Offenbar rechneten einige Marktteilnehmer mit negativen Reaktionen der Märkte und gaben Stücke bei sehr geringer Handelstätigkeit aus der Hand. Dies habe den Gesamtmarkt im frühen Verlauf unter Druck gesetzt. Gleich nach den ersten Zahlen um 14:30 Uhr, bei denen die US-Verbraucherpreise im Juli mit einem Anstieg u\n",
      "\n",
      "\n",
      "Aktien Frankfurt Schluss: Mit moderatem Plus --3(Karstadt, Linde, Kam ps). (Fortsetzung) - Zu den wenigen Verlierern im Dax zählte heute der Kaufhauskonzern Karstadt <KAR.ETR>. Die Aktie büßte 7,99 Euro auf 461,50 Euro ein. Die Münchener Investmentbank Merck Finck & Co hatte Karstadt als «Marketperformer» bestätigt und geäußert, die Ankündigungen des Einzelhandelskonzerns seien nach wie vor «nicht sehr transparent». Ebenfalls im Minus Linde <LIN.ETR>, die 90 Cent auf 57,10 Euro abgaben. Das Unternehmen hatte am Nachmittag mitgeteilt, die Ems-Syntech übernehmen zu wollen. Finanzielle Einzelheiten wurden nicht genannt. Linde werde zunächst 80% der Ems-Syntech akquirieren, die restlichen 20% dann innerhalb der nächsten zwei Jahre. Die Aktie der Metallgesellschaft <MET.ETR> konnte zuletzt 11 Cent auf 20,90 Euro zulegen. Auf der außerordentlichen Hauptversammlung der mg stimmten heute Nachmittag 99,9% der anwesenden oder vertretenen Aktionäre für die Fusion mit der Gea AG. Gea-Vorzüge <GEA3\n",
      "\n",
      "\n",
      "---- Ad hoc messages ----\n",
      "\n",
      "\n",
      "Ad hoc-Service Computec Media AG <CMD > Teil 2. (Fortsetzung) - durchschnittlich zwei Internet-Spiele pro Jahr erweitern. Business Unit CD-PUBLISHING Innerhalb der Business Unit CD-PUBLISHING wurde im 9-Monats-Zeitraum ein Umsatz von 415 TDM und ein Ergebnis der operativen Tätigkeit von -237 TDM erzielt. Das Geschäft mit Erweiterungssoftware zu populären Spielen blieb damit deutlich hinter den Erwartungen zurück. Die Geschäftsentwicklung wurde dabei durch den Wechsel des Vertriebspartners und die damit verbundenen Verzögerungen in der Veröffentlichung von Produkten beeinträchtigt. Mehrere Softwaretitel konnten erst in der schwachen Frühling-/Sommer-Saison veröffentlicht werden und erreichten deswegen nicht den geplanten Absatz. In den Folgequartalen rechnet COMPUTEC MEDIA in diesem Segment jedoch wieder mit deutlich ansteigenden Umsatzerlösen. Der vollständige Quartalsbericht steht ab sofort auf der Website des Unternehmens unter www.computec.de/Investor Relations/Berichte und Präsenta\n",
      "\n",
      "\n",
      "Ad hoc-Service Austria Tabak AG <ATK > --2. 1893 Date: 19990820 Time: 08530630 ISIN: AT0000619200 Market: VIE Number: 5048 SubNumber: 02 Headline: Ad hoc-Service: Austria Tabak AG <ATK > deutsch n Geschäftsbe- reich Großhandel um rund zehn Prozent verbessern. Ohne Berücksichtigung von Amortisationsquoten betreffend den sich aus den Fusionen ergebenden Goodwill wird sich das Periodenergebnis bzw. der Jahresüberschuß 1999 - jeweils nach Minderheitsanteilen - im Großhandel jedoch nicht wesentlich verändern. Die Akquisition in Schweden wird im Geschäftsbereich Tabakindustrie auf Jahresbasis das Absatzvolumen um rund 30 Prozent und die Kennzahl EBITDA um ca. 65 Prozent erhöhen. Dieser operativen Ergebnisverbesserung, die sich im 2. Halbjahr 1999 voll in der Konzernrechnung niederschlagen wird, stehen jedoch Goodwill-Abschreibungen und Finanzierungskosten gegenüber. Nennens- werte Auswirkungen auf das Jahresergebnis 1999 werden aufgrund von Einmal- kosten im Anfangsjahr nicht erwartet. Vom A\n",
      "\n",
      "\n",
      "---- Stock market analysis, recommendations for traders ----\n",
      "\n",
      "\n",
      "AKTIE IM FOKUS/Clariant mit Gewinnen nach BTP-Übernahmeofferte. ZÜRICH (dpa-AFX) - Die Aktien der Clariant AG <CLN.ZRH> reagieren mit Gewinnen auf die von beiden involvierten Partnern bestätigte Übernahmeofferte für die britische BTP PLC. Laut den Verlautbarungen unterbreitet Clariant für die BTP eine Cash-Übernahmeofferte in der Höhe von 600 Pence pro BTP-Aktie, was gesamthaft einen Übernahmepreis von 1,08 Mrd GBP ergibt. Um 09.15 Uhr notiert die Aktie 6 CHF bzw. 0,82 Prozent höher auf 734 CHF. Der SMI gewinnt 0,4 Prozent auf 7.264,70 Zähler. Laut einem Handelsanalysten einer Schweizer Grossbank sei die angekündigte Übernahme in strategischer Hinsicht bestimmt ein guter Deal für Clariant, dies gelte sowohl hinsichtlich geographischer als auch produktespezifischer Überlegungen. Hingegen sei der Übernahmepreis relativ hoch. Die Eigenkapitalquote von Clariant werde bestimmt deutlich sinken und sehrwahrscheinlich müsse Clariant schon bald auf dem Kapitalmarkt aktiv werden. «Qualität ist h\n",
      "\n",
      "\n",
      "AKTIE IM FOKUS: Aus Mannesmann-Aktie weicht nach Übernahmeschlacht di e Luft. DÜSSELDORF (dpa-AFX) - Angesichts einer möglichen Einigung in der Übernahmeschlacht um Mannesmann <MMN.ETR> durch Vodafone <VOD.ISE> weicht aus der steil gestiegenen Aktie des Düsseldorfer Telekommunikationskonzerns die Luft. Zwar stieg das Papier am Frankfurter Aktienmarkt am Donnerstag zunächst noch um 4,3 Prozent auf 340 Euro. Die Aktie fiel dann aber unter 300 Euro zurück. Sie lag um 13.58 Uhr bei 306 Euro und damit 5,84 Prozent tiefer als am Vortag. Rund 1,76 Milliarden Aktien wurden bis zum frühen Nachmittag gehandelt. Bei Bekanntwerden der Übernahmenpläne von Vodafone am 22. Oktober 1999 hatte die Mannesmann-Aktie mit 144 Euro notiert. Die Vodafone-Aktie büßte am Donnerstag in Frankfurt 6,79 Prozent oder 0,43 Euro auf 5,90 Euro ein. Von ihr wurden rund 3,72 Millionen Papiere gehandelt. «Derzeit gehen einige Portfolio-Manager aus Mannesmann raus, weil sie keine Vodafone-Aktien halten dürfen», berichtete\n",
      "\n",
      "\n",
      "---- News on companies ----\n",
      "\n",
      "\n",
      "ROUNDUP: Siemens will beim Umsatz in 1999/00 einstellig zulegen. MÜNCHEN (dpa-AFX) - Für das angelaufene Geschäftsjahr 1999/00 erwartet der Siemens-Konzern <SIE.ETR> ein einstelliges Umsatzwachstum und ein darüber liegendes Ergebniswachstum. Aufgrund wirksam werdender Desinvestitionen sollen Auftragseingang und Umsatz allerdings rechnerisch unter dem jeweiligen Vorjahreswert liegen, sagte Konzernchef Heinrich von Pierer am Donnerstag auf der Bilanzpressekonferenz in München. Aus den bislang getätigten Desinvestitionen erwartet Siemens für das laufende Geschäftsjahr 1999/00 nach Angaben von Finanzchef Heinz-Joachim Neubürger außerordentliche Nachsteuererträge von mindestens 3 Mrd. DM. «Die genaue Höhe der Sondererträge hängt vor allem vom Infineon-Börsengang ab,» sagte von Pierer. Von den insgesamt im Rahmen des 10-Punkte-Programms vom Sommer 98 geplanten Desinvestitionen sei bereits ein Teil abgeschlossen oder grundsätzlich vereinbart. Hier nannte von Pierer den Verkauf der Sparte Elek\n",
      "\n",
      "\n",
      "ROUNDUP: Intel erwartet im ersten Quartal Umsatzminus - Lagerbestände. FRANKFURT (dpa-AFX) - Die Intel Corp. <INTC.NAS> erwartet im ersten Quartal 2000 einen Umsatz leicht unter dem des Vorquartals. Das Unternehmen nannte als Grund dafür am Donnerstagabend zwar saisonale Faktoren. Die Aussage dürfte aber Investoren enttäuscht haben, die auf einem Chip-Boom nach dem Jahr-2000-Problem gehofft hatten. Intel-Finanzchef Andy Bryant sagte in einer Telefonkonferenz mit Analysten immerhin, der Umsatzrückgang werde im ersten Quatals 2000 nicht so stark sein wie im Vorjahreszeitraum, als der Umsatz des ersten Quartals 1999 gegenüber dem des vierten Quartals 1998 um sieben Prozent zurückging. Die Bruttomarge sollte im ersten Quartal im Vergleich zur Marge von 61,3% im vierten Quartal nahezu unverändert bleiben. Im Gesamtjahr 2000 werde sie im Mittel 61% «plus oder minus ein paar Punkte» erreichen, sagte Bryant. 1999 lag sie bei 59,7%. Analysten erwarten eine festere Notiz der Aktie am Freitag. Al\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Stock_market = data[(data.texts.str.contains('^Aktien')) & (data.topic == 'afx')]\n",
    "Ad_hoc = data[(data.texts.str.contains('Ad hoc-Service')) & (data.topic == 'afx')]\n",
    "Analysis = data[(data.texts.str.contains('^AKTIE IM FOKUS')) & (data.topic == 'afx')]\n",
    "Companies = data[(data.texts.str.contains('ROUNDUP')) & (data.topic == 'afx')]\n",
    "\n",
    "print('---- Articles on the stock market ----')\n",
    "print('\\n')\n",
    "print(Stock_market.reset_index()['texts'][0][:1000])\n",
    "print('\\n')\n",
    "print(Stock_market.reset_index()['texts'][100][:1000])\n",
    "print('\\n')\n",
    "print('---- Ad hoc messages ----')\n",
    "print('\\n')\n",
    "print(Ad_hoc.reset_index()['texts'][0][:1000])\n",
    "print('\\n')\n",
    "print(Ad_hoc.reset_index()['texts'][1][:1000])\n",
    "print('\\n')\n",
    "print('---- Stock market analysis, recommendations for traders ----')\n",
    "print('\\n')\n",
    "print(Analysis.reset_index()['texts'][0][:1000])\n",
    "print('\\n')\n",
    "print(Analysis.reset_index()['texts'][1][:1000])\n",
    "print('\\n')\n",
    "print('---- News on companies ----')\n",
    "print('\\n')\n",
    "print(Companies.reset_index()['texts'][0][:1000])\n",
    "print('\\n')\n",
    "print(Companies.reset_index()['texts'][10][:1000])\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we can conclude that these types of articles are of interest to financial market participants, but may be too detailed for the general public.\n",
    "\n",
    "A few exceptions, which we also consider, are afx articles on business cycle (Konjunktur) and Politics.\n",
    "\n",
    "* Articles on business cycle might be very important for economic forecasting. We therefore considered including news reports with the keyword 'Konjunktur' (business cycle) published by afx. However, we encountered two problems.\n",
    "\n",
    "* First, articles with the keyword 'Konjunktur' aimed at the general public often enter our database twice because they are published by both dpa and afx. Articles published exclusively by afx are often more quantitative and seem to target financial market participants. \n",
    "\n",
    "* Second, while the proportion of dpa articles with the keyword 'Konjunktur' is relatively stable and ranges from 0.5% to 4% (see 'dpa' column in the dataframe below), the proportion of 'Konjunktur' articles in afx data increases significantly from 3% in 2000 to 17% in 2018 (see 'afx' column). We believe this is due to the fact that in the afx data, the keyword 'Konjunktur' was initially used only in the articles with a lot of quantitative information, and then began to be used in a much wider range of articles. In any case, if we included all dpa articles and afx articles with the keyword 'Konjunktur', we would see that the share of articles with the keyword 'Konjunktur' increases over the years (see 'All' column), most likely due to structural changes in the database rather than economic developments. Therefore, we decided to exclude afx articles with the keyword 'Konjunktur' from further analysis.\n",
    "\n",
    "* We also exclude afx articles with the keyword 'Politik', because in most cases dpa publishes the same articles. Thus, these articles can be considered as duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>All</th>\n",
       "      <th>dpa</th>\n",
       "      <th>afx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>0.006792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993</td>\n",
       "      <td>0.008649</td>\n",
       "      <td>0.008649</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>0.007132</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.019581</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.026148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.053510</td>\n",
       "      <td>0.017835</td>\n",
       "      <td>0.073957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2002</td>\n",
       "      <td>0.071646</td>\n",
       "      <td>0.011748</td>\n",
       "      <td>0.103475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>0.076932</td>\n",
       "      <td>0.016636</td>\n",
       "      <td>0.099307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2004</td>\n",
       "      <td>0.082734</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.098102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2005</td>\n",
       "      <td>0.080661</td>\n",
       "      <td>0.014812</td>\n",
       "      <td>0.092058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2006</td>\n",
       "      <td>0.072064</td>\n",
       "      <td>0.011452</td>\n",
       "      <td>0.082136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2007</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.010817</td>\n",
       "      <td>0.080009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2008</td>\n",
       "      <td>0.097297</td>\n",
       "      <td>0.022387</td>\n",
       "      <td>0.091763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2009</td>\n",
       "      <td>0.115635</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>0.099218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2010</td>\n",
       "      <td>0.126047</td>\n",
       "      <td>0.017640</td>\n",
       "      <td>0.123427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2011</td>\n",
       "      <td>0.125431</td>\n",
       "      <td>0.015552</td>\n",
       "      <td>0.125882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012</td>\n",
       "      <td>0.158348</td>\n",
       "      <td>0.015423</td>\n",
       "      <td>0.158927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2013</td>\n",
       "      <td>0.156110</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.149316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.145639</td>\n",
       "      <td>0.020450</td>\n",
       "      <td>0.139694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015</td>\n",
       "      <td>0.165532</td>\n",
       "      <td>0.015325</td>\n",
       "      <td>0.152256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.158726</td>\n",
       "      <td>0.014061</td>\n",
       "      <td>0.149808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>0.176299</td>\n",
       "      <td>0.011951</td>\n",
       "      <td>0.155680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.206701</td>\n",
       "      <td>0.012932</td>\n",
       "      <td>0.177515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year       All       dpa       afx\n",
       "0   1991  0.005356  0.005356       NaN\n",
       "1   1992  0.006792  0.006792       NaN\n",
       "2   1993  0.008649  0.008649       NaN\n",
       "3   1994  0.007132  0.007132       NaN\n",
       "4   1995  0.006451  0.006451       NaN\n",
       "5   1996  0.007627  0.007627       NaN\n",
       "6   1997  0.007536  0.007536       NaN\n",
       "7   1998  0.010032  0.010032       NaN\n",
       "8   1999  0.007640  0.007640       NaN\n",
       "9   2000  0.019581  0.008571  0.026148\n",
       "10  2001  0.053510  0.017835  0.073957\n",
       "11  2002  0.071646  0.011748  0.103475\n",
       "12  2003  0.076932  0.016636  0.099307\n",
       "13  2004  0.082734  0.014188  0.098102\n",
       "14  2005  0.080661  0.014812  0.092058\n",
       "15  2006  0.072064  0.011452  0.082136\n",
       "16  2007  0.074380  0.010817  0.080009\n",
       "17  2008  0.097297  0.022387  0.091763\n",
       "18  2009  0.115635  0.036890  0.099218\n",
       "19  2010  0.126047  0.017640  0.123427\n",
       "20  2011  0.125431  0.015552  0.125882\n",
       "21  2012  0.158348  0.015423  0.158927\n",
       "22  2013  0.156110  0.017964  0.149316\n",
       "23  2014  0.145639  0.020450  0.139694\n",
       "24  2015  0.165532  0.015325  0.152256\n",
       "25  2016  0.158726  0.014061  0.149808\n",
       "26  2017  0.176299  0.011951  0.155680\n",
       "27  2018  0.206701  0.012932  0.177515"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proportion of articles with the keyword 'Konjunktur' in the whole dataset.\n",
    "Konjunktur_all_series = data[(data.keywords.str.contains('Konjunktur'))].drop(columns =['paragraphs']).groupby('year').nunique()['texts']/data[(data.topic == 'WiPo') | ((data.topic == 'afx') & (data.keywords.str.contains('Konjunktur')))].drop(columns =['paragraphs']).groupby('year').nunique()['texts']\n",
    "Konjunktur_all_df = Konjunktur_all_series.to_frame().reset_index()\n",
    "Konjunktur_all_df = Konjunktur_all_df.rename(columns = {\"texts\": \"All\"})\n",
    "# The proportion of articles with the keyword 'Konjunktur' in dpa dataset.\n",
    "Konjunktur_dpa_series = data[(data.keywords.str.contains('Konjunktur')) & (data.topic == 'WiPo')].drop(columns =['paragraphs']).groupby('year').nunique()['texts']/data[(data.topic == 'WiPo')].drop(columns =['paragraphs']).groupby('year').nunique()['texts']\n",
    "Konjunktur_dpa_df = Konjunktur_dpa_series.to_frame().reset_index()\n",
    "Konjunktur_dpa_df = Konjunktur_dpa_df.rename(columns = {\"texts\": \"dpa\"})\n",
    "# The proportion of articles with the keyword 'Konjunktur' in afx dataset.\n",
    "Konjunktur_afx_series = data[(data.keywords.str.contains('Konjunktur')) & (data.topic == 'afx')].drop(columns =['paragraphs']).groupby('year').nunique()['texts']/data[(data.topic == 'afx')].drop(columns =['paragraphs']).groupby('year').nunique()['texts']\n",
    "Konjunktur_afx_df = Konjunktur_afx_series.to_frame().reset_index()\n",
    "Konjunktur_afx_df = Konjunktur_afx_df.rename(columns = {\"texts\": \"afx\"})\n",
    "# The dataframe with the above mentioned datafames merged together.\n",
    "merged_df = Konjunktur_all_df.merge(Konjunktur_dpa_df, how = 'left', on = 'year')\n",
    "merged_df = merged_df.merge(Konjunktur_afx_df, how = 'left', on = 'year')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, we only keep articles published by dpa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211719\n"
     ]
    }
   ],
   "source": [
    "data = data[data.topic == 'WiPo']\n",
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True) # reset the index of the DataFrame\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('dpa_prepro_step6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dpa_prepro_step6.csv', encoding = 'utf-8', index_col = 0,  keep_default_na=False,\n",
    "                   dtype = {'rubrics': 'str', \n",
    "                            'source': 'str',\n",
    "                            'keywords': 'str',\n",
    "                            'title': 'str',\n",
    "                            'city': 'str',\n",
    "                            'genre': 'str',\n",
    "                            'wordcount': 'str'},\n",
    "                  converters = {'paragraphs': literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Delete non-German Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we filter out articles written in any language other than German using a **langdetect** library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the following types of articles:\n",
    "\n",
    "1) articles about American elections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vorläufige Verteilung der 538 Wahlmänner und -frauen: Washington (dpa) - Die vorläufige Verteilung der 538 Wahlmänner und -frauen: Staat Clinton Bush 1988: Alabama 9 Bush Alaska 3 Bush Arizona 8 Bush Arkansas 6 Bush California 54 Bush Colorado 8 Bush Connecticut 8 Bush Delaware 3 Bush Distric of Columbia 3 Dukakis Florida 25 Bush Georgia noch nicht entschieden (13) Bush Hawaii 4 Dukakis Idaho 4 Bush Illinois 22 Bush Indiana 12 Bush Iowa 7 Dukakis Kansas 6 Bush Kentucky 8 Bush Louisiana 9 Bush Maine 4 Bush Maryland 10 Bush Massachusetts 12 Dukakis Michigan 18 Bush Minnesota 10 Dukakis Mississippi 7 Bush Missouri 11 Bush Montana 3 Bush Nebraska 5 Bush Nevada 4 Bush New Hampshire 4 Bush New Jersey 15 Bush New Mexico 5 Bush New York 33 Dukakis North Carolina 14 Bush North Dakota 3 Bush Ohio 21 Bush Oklahoma 8 Bush Oregon 7 Dukakis Pennsylvania 23 Bush Rhode Island 4 Dukakis South Carolina 8 Bush South Dakota 3 Bush Tennessee 11 Bush Texas 32 Bush Utah 5 Bush Vermont 3 Bush Virginia 13 Bush Washington 11 Dukakis West Virginia 5 Dukakis Wisconsin 11 Dukakis Wyoming 3 Bush Summe ohne Georgia 357 168 Bush: 426 Dukakis : 111 andere: 1'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.file == '6385957.xml'].iloc[0]['texts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) articles written in Low German (Plattdeutsch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"«Westfalen-Blatt» (Bielefeld) zu Plattdeutsch im Bundestag. do koennsse duessen fridag in'n bunnes-dage chanz unchewuehnlicke toene heuern: de damens un herrens awjeordneten haet ssick de wohrheit ens mohl platt vo'n kopp sseggt. dobui gueng et oemme de niederduetske sproke (wick dat uise platt «amtlick» neumt wei- hert...). et, dat niederduetske, schall met olle annern regionol- sproken «gliek up gliek» stellt weihern, unjefaehr met denn, watter dat «gaelische» or dat «baskische» es, un (nich to vagieden) met denn «sorbischen», watter bit tae-u inner duetsken sproken-kultur, oll laengest, osser ne eigen sproke gellen doett. woroemme datse do-oarber kueart? weil et iut de raude kassen in bruesel fo dat wahr'n un bluiben van de ae-ulen, «wossenen» sproken, ne masse cheld giw. ober schiube wui dat mohl uppe ssuit: platt beduett jo nich platzt, weil't, in'n giegendeil to'n haeuggen, ne «un-kultur» weuher. ssoennern platt, dat es de sproke, de uppen flacken, platten lanne to huis es. un dat drawse nich oemmedreihen: platt haew nix met ner «platituede», watse hae-ugduetsk ssegget, to dohn. plattheiten bringetse gewuehnlickhenn ne masse meiher up hae-ugge uenner't volk. to'n beispell: ''du sollst die platte putzen'' - nen sprichweihert, da wui up duesse wuise, in iuse plattduetske sproke nich kinnt, un watter niemols einer up platt sseggen wuedde. ssae-u schein et denn derbe neudig, dat de duitske bunnes-dag mohl ssuine gewuehnlicken parlaments-gewuhnheiten uppe ssuitt stellt, un up platt oarber platt kueart haew. lesstennlick ssinter in duitskland noroh acht bit teijen millijaeunen minsken, de platt kueart. un doroemme bliwwer uennern strich: eine, de hae-ugge, un plattduetsk kuearn kann (un doroemme tweisprokig es), dat esser nae-u lange nich nen doeskopp.\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.file == '6808045.xml'].iloc[0]['texts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) articles written in German and translated into English or French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'David Levy: Treffen mit Arafat innerhalb von zwei Wochen. Jerusalem (dpa) - Der israelische Außenminister David Levy will sich innerhalb von zwei Wochen mit dem Präsident der palästinensischen Selbstverwaltungsbehörde Jassir Arafat treffen. Levy teilte am Donnerstag im israelischen Rundfunk außerdem mit, daß ein Treffen zwischen Regierungschef Benjamin Netanjahu und Arafat möglicherweise noch eher zustande komme. Levy sagte, es würden große Anstrengungen unternommen, um das Treffen zu ermöglichen. Seit der Wahl Netanjahus Ende Mai hat es keine hochrangigen Kontakte zwischen Israel und dem Palästinensischen Autonomiekabinett gegeben. Der israelische Außenminister sagte außerdem, daß eine Lösung für den Rückzug der israelischen Armee aus Hebron möglicherweise bevorstehe. In Jerusalem hieß es weiter, daß der amerikanische Präsident Bill Clinton Netanjahu während seiner Gespräche in Washington gedrängt habe, sich mit Arafat zu treffen und eine Lösung für den vereinbarten Rückzug aus Hebron zu finden. dpa ag ub Israeli foreign minister David Levy will meet with Palestinian president Yassir Arafat within two weeks, and premier Binyamin Netanyahu is likely to do so even earlier, Levy has said in a television interview. Speaking late Wednesday night on state run Israel television Levy said that intensive contacts were under way to arrange the meeting. HHe also said that a solution to the problem of withdrawing from the West Bank town of Hebron was being formed. Since the election of the right wing government in late May almost no high level contacts between Israel and the Palestinian Authority have taken place. U.S. president Bill Clinton is reported to have pressed Netanyahu in the ir current Washington talks to meet Arafat in the near future and also to implement the delayed redeployment in the Hebron. Palestinian official Sufian Abu Zeida played down the importance of a Netanyahu-Arafat meeting. Speaking on Israel Radio Abu Zeida, who heads the Israel desk in the Palestinian Authority, said it was more important that Israel start negotiations on the permanent status settlement and fulfills its existing obligations under the autonomy agreement. dpa ag goldberg 110701 Jul 96'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.file == '3959856.xml'].iloc[0]['texts']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) articles written in English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Davos: Israeli/Palestinian business council suggested (414) GUARDIAN NEWS SERVICE (DAVOSMIDEAST) By Jane Martinson in Davos. A new council uniting Israeli and Palestinian businesses is to be formed under proposals to stimulate investment in the Middle East put forward at the World Economic Forum (WEF) yesterday. The meeting saw Tzipi Livni, the Israeli foreign minister, and Mahmoud Abbas, the Palestinian president, pledge to work harder towards a settlement. The session ended with the WEF\\'s founder, Klaus Schwab, appearing to promise to move the forum\\'s money-spinning annual meeting from Davos to Jerusalem next year. The understanding is that the move could take place as long as there had been \"progress\" on peace, which is likely to take significantly more than a year. The forum has only once moved the annual meeting in its 36-year history, when it moved to New York after 9/11. \"Next year in Jerusalem. This is our goal,\" said Ms Livni yesterday. Mr Schwab had earlier confirmed that the forum was in the \"late stages\" of creating a business council to encourage cooperation between both sides. The plan followed an emotional plea by the Israeli political veteran and potential presidential contender Shimon Peres for Davos members, who are said to represent a quarter of the world\\'s gross domestic product, to invest in the region. \"Hope for me is like snow that comes from the top of the mountain, the magic mountain.\" Before becoming synonymous with an annual meeting of the world\\'s most influential people, Davos was the inspiration for Thomas Mann\\'s Magic Mountain. He said the region needed economic as well as political development. \"If I want to speak politics, I go to the UN,\" he said. \"If I want to speak about economic issues, I come to Davos.\" He argued that the region\\'s 300 million Arabs - a number set to double in 10 years - should provide an attractive emerging market once \"obstacles are removed\". The business council being planned by the forum is set to include Yossi Vardi, an Israeli hi-tech entrepreneur, and Abdul Malek Jabr, a Palestinian businessman. The forum is also represented. All three participants were shown videos created by One Voice of Israelis and Palestinians calling for a two-state solution. Daniel Lubetzky, president of the charitable movement designed to encourage economic investment in the area, welcomed the tone of the Davos meeting. Ms Livni said a Palestinian state was \"achievable\" while Mr Abbas said economic progress was needed to strengthen moderates in the region - 70% of Gaza\\'s inhabitants live below the poverty line.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.file == '5429862.xml'].iloc[0]['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:46:38.942938\n"
     ]
    }
   ],
   "source": [
    "# Delete all non-German articles from the data  \n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    ger_results = pool.map(identify_ger.identify_ger, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "2211695\n"
     ]
    }
   ],
   "source": [
    "data['language'] = ger_results\n",
    "# the number of non-German articles\n",
    "print(len(data[data.language == 0]))\n",
    "# keep articles written in German\n",
    "data = data[data.language==1]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('dpa_prepro_step7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dpa_prepro_step7.csv', encoding = 'utf-8', index_col = 0,  keep_default_na=False,\n",
    "                   dtype = {'rubrics': 'str', \n",
    "                            'source': 'str',\n",
    "                            'keywords': 'str',\n",
    "                            'title': 'str',\n",
    "                            'city': 'str',\n",
    "                            'genre': 'str',\n",
    "                            'wordcount': 'str'},\n",
    "                  converters = {'paragraphs': literal_eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify articles that predominantly consist of numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles that predominantly consist of numerical data present challenges for sentiment or topic analysis as, once numbers are removed, they tend to contain limited information. Moreover, the topics covered in these articles are often not relevant to our research question. Examples of such topics include budget distribution plans, statistics on car registrations, tax reforms in numbers and examples, statistics on oil and gas imports, history of key interest rate changes, and distribution of seats in the parliament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exploring news articles with a high proportion of numbers, we noticed a text in which all the \"i\"s were replaced with \"1\"s. We decided to delete this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zusammenfassung Südkorean1sche Reg1erungsparte1 ohne Mehrhe1t 1m neuen Parlament. Seoul (dpa) - In Südkorea hat d1e reg1erende Neue Korea Parte1 (NKP) von Staatschef K1m Young Sam 1hre parlamentar1sche Mehrhe1t 1n der neugewählten Nat1onalversammlung verloren, ble1bt aber we1ter an der Reg1erung. Präs1dent K1m sagte am Fre1tag 1n e1ner ersten Reakt1on zum Wahlergebn1s, er werde se1ne Reformpol1t1k und Kampagne gegen d1e Korrupt1on entsch1eden fortsetzen. Er sehe d1e Entsche1dung der Wähler als Auftrag für «Reformen und zur Schaffung e1ner sauberen pol1tschen Trad1ton». K1m darf laut Verfassung nach Ablauf se1ner fünfjähr1gen Amtsze1t 1998 ke1n zwe1tes Mal kand1d1eren. D1e NKP w1rd 1m neuen, 299 S1tze zählenden Parlament statt mit bisher 150 Mandaten nur noch m1t 139 vertreten se1n. M1t 79 S1tzen als zwe1tgrößte Parte1 etabl1erte s1ch der von K1ms angeschlagenem R1valen K1m Dae Jung angeführte oppos1t1onelle Nat1onalkongreß für neue Pol1t1k (NCNP). Zwe1 andere oppos1t1onelle Gruppen - d1e Vere1nten L1beraldemokraten (ULD) und die Demokrat1sche Pate1 (DP) - gewannen nach dem am Fre1tag veröffentl1chten off1z1ellen Wahlergebn1s 50 beziehungsweise 15 Mandate. H1nzu kommen 16 Unabhäng1ge. D1e Führungsgrem1en der v1er südkorean1schen Parte1en, von denen ke1ne e1ne Mehrhe1t 1m Parlament gewann. sind jetzt offenbar bemüht, möglichst v1ele unabhäng1ge Parlamentar1er auf 1hre Se1te zu z1ehen. Auf d1ese We1se hatte s1ch die Regierungspartei bereits nach ihrem schwachen Abschneiden bei den letzten Parlamentswahlen 1992 1hre spätere parlamentar1sche Mehrhe1t aufgebaut. Vor den Wahlen hatten Me1nungsumfragen der NKP e1ne klare Wahln1ederlage und als Folge e1ne mögl1che pol1t1sche Instab1ltät vorausgesagt. Vor d1esem H1ntergrund schn1tt Präs1dent K1ms Parte1 be1 den Wahlen am Donnerstag bemerkenswert gut ab. D1e jüngsten nordkorean1schen Verletzungen des Waffenst1llstandsabkommens und Spannungen 1n der entm1l1tar1s1erten Zone zw1schen Nord- und Südkorea brachten der auf pol1t1sche Stab1ltät setzenden NKP laut südkorean1schen Analysen zusätzl1che St1mmen konservat1ver Wähler. Vor den Wahlen hatte s1ch Oppos1t1onsführer K1m Dae Jung für se1ne NCNP m1ndestens 100 Mandate und dam1t e1ne sol1de pol1t1sche Plattform für se1ne Amb1t1onen bei der Präsidentenwahl 1997 erhofft. Stattdessen wurde der NCNP 1n Seoul so empf1ndl1ch geschlagen, daß K1m ke1ne Auss1cht auf e1n Abgordnetenmandat hat.'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The article to delete\n",
    "file_drop = ['3874051.xml']\n",
    "ind = data[data.file == '3874051.xml']['texts'].index[0]\n",
    "data[data.file == '3874051.xml']['texts'][ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data[data['file'].isin(file_drop)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:48.135737\n"
     ]
    }
   ],
   "source": [
    "# use the 'numeric_articles' function to identify economic articles with a high share of numbers in them\n",
    "inputs = zip(data['texts'], data['word_count'], itertools.repeat(0.50))\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    numeric_list = pool.starmap(numeric_articles.numeric_articles, inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)\n",
    "data['numeric'] = numeric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Höchste Arbeitslosenquote im Ostteil Berlins. Nürnberg (dpa) - Von den neuen Bundesländern hat Sachsen mit 6,2 Prozent im Dezember die niedrigste Arbeitslosenquote. Überdurchschnittlich ist die Erwerbslosigkeit im Ostteil Berlins (Quote 9,3 Prozent) und in Mecklenburg-Vorpommern (8,7). Da sich die Berechnung anders als in Westdeutschland auf alle zivilen Erwerbspersonen bezieht, können die Quoten der alten und neuen Bundesländer nicht miteinander verglichen werden. Die Arbeitslosigkeit stieg im Dezember gegenüber dem Vormonat in Schleswig-Holstein um 5 173 auf 88 718 (Quote 8,2 Prozent), in Hamburg um 1 429 auf 68 246 (9,5), in Niedersachsen um 13 708 auf 259 466 (8,8), in Bremen um 112 auf 34 492 (12,0), in Nordrhein-Westfalen um 14 338 auf 583 880 (8,4), in Hessen um 7 058 auf 127 740 (5,4), in Rheinland-Pfalz um 9 019 auf 89 757 (6,0), im Saarland um 615 auf 36 403 (8,7), in Baden-Württemberg um 9 823 auf 167 776 (4,0), in Nordbayern um 18 065 auf 116 774 (5,6), in Südbayern um 17 175 auf 121 772 (4,6) und in (West)Berlin um 2 511 auf 89 126 (9,2).'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect example article with high share of numbers\n",
    "data[data.numeric == True]['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Öleinfuhren größer und teurer. Wiesbaden (dpa/vwd) - Mehr Öl zu höheren Preisen haben die alten Bundesländern im vergangenen Jahr eingeführt. In den ersten elf Monaten von 1990 erhöhten sich die Rohölimporte im Jahresvergleich um 9,0 Prozent auf 65,5 Millionen Tonnen. Die Ölrechnung für diesen Zeitraum fiel mit 17,8 Milliarden DM um 2,4 Milliarden DM höher aus als ein Jahr zuvor. Von Januar bis November lag der Durchschnittspreis für die Tonne Importrohöl mit 272,39 DM um 6,3 Prozent höher als im Vorjahr (256,28 DM). Allein im November registrierte das Statistische Bundesamt nach Mitteilung vom Donnerstag in Wiesbaden einen um 48,0 Prozent über dem Vorjahresniveau liegenden Durchschnittspreis. Einfuhr nach Ursprungsländern Jan.-Nov. 90 Jan.-Nov. 89 in 1 000 Tonnen 1. Großbritannien 13 860 12 721 2. Libyen 10 546 10 025 3. Saudi-Arabien 5 539 5 082 4. Norwegen 5 414 4 969 5. Nigeria 5 413 4 020 6. Sowjetunion 5 057 5 418 7. Venezuela 4 019 4 352 8. Syrien 3 226 2 136 9. Algerien 3 146 3 544 10. Iran 2 744 2 050 11. Nordjemen 2 572 1 829 12. Arab. Emirate 743 899 13. Angola 624 249 14. Mexiko 475 273 15. Kuwait 393 618 16. Ägypten 389 596 17. Gabun 228 - 18. Irak 219 576 19. Katar 126 64 20. Kamerun 119 - 21. Dänemark 115 - 22. Südjemen 109 492 23. Australien 105 - 24. Oman 77 - 25. Tunesien 68 135 26. Indonesien 62 - 27. Malaysia 59 - 28. Italien 32 28 Niederlande - 26 Gesamt: 65 494 60 112 Durchschnittspreis pro Tonne 272,39 DM 256,28 DM'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.numeric == True]['texts'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[data.numeric == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2211420\n"
     ]
    }
   ],
   "source": [
    "# drop articles predominantly consisting of numbers\n",
    "data = data[data.numeric == False]\n",
    "del data['numeric']\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we exclude the tables from the news articles in order to reduce noise and focus on important information. To do that, we identify the articles that contain at least one paragraph that is predominantly comprised of numbers and that is at least 10 words long. Then we manually examine these articles to identify common strings that often precede tables. Finally, we use regular expressions to delete the tables based on these strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:50.842181\n"
     ]
    }
   ],
   "source": [
    "inputs = zip(data['paragraphs'], itertools.repeat(0.70), itertools.repeat(10))\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    numeric_par = pool.starmap(numeric_par.numeric_par, inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)\n",
    "data['numeric_par'] = numeric_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_par = data[data.numeric_par == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_par.loc[:,'file'].to_csv('quant_par.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples of articles containing at least one paragraph that is predominantly comprised of numbers and that is at least 10 words long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Auftragseingänge im November rückläufig - deutlich weniger Auslandsbestellungen. Bonn (dpa/vwd) - Die Auftragseingänge beim Verarbeitenden Gewerbe in den alten Bundesländern sind im November gegenüber dem Vormonat preis- und saisonbereinigt um 3,5 Prozent zurückgegangen. Dies geht aus vorläufigen Berechnungen des Statistischen Bundesamtes hervor, die am Dienstag vom Bundeswirtschaftsministerium veröffentlicht wurden. Dabei gingen den Angaben zufolge die Bestellungen des Auslands deutlich um 7,5 Prozent zurück. Ausschlaggebend dafür dürfte nach Angaben des Ministeriums die spürbar abgekühlte Konjunktur in einer Reihe wichtiger Partnerstaaten sein. Die Inlandsbestellungen gingen im Berichtsmonat um 1,5 Prozent zurück. Auch der Zweimonatsvergleich (Oktober/November gegenüber August/September), in dem kurzfristige Schwankungen ausgeglichen werden, zeige, daß sich die inländischen Auftragseingänge auf dem hohen Niveau der Vorperiode hielten, während die Auslandsbestellungen um vier Prozent zurückgingen. Insgesamt ergab sich daraus eine Auftragsrückghang beim Verarbeitenden Gewerbe um 1,5 Prozent. Im Grundstoff- und Produktionsgüterbereich blieben die Bestellungen unverändert. Der Investitionsgütersektor verzeichnete einen Auftragsrückgang um 2,5 Prozent. Dagegen verbuchte das Verbrauchsgütergewerbe eine leichte Zunahme (0,5 Prozent). Ihren entsprechenden Vorjahresstand überschritten die Auftragseingänge im Oktober/November dem Volumen nach um 8,6 Prozent. Die Inlandsbestellungen verzeichneten dabei binnen Jahresfrist einen weit überdurchschnittlichen Zuwachs, während die Auslandsorders etwas niedriger ausfielen als ein Jahr zuvor. Im einzelnen ergaben sich folgende Veränderungen (in Prozent): Oktober + November 1990/ Oktober + November 1989 Volumen Wert Verarbeitendes Gewerbe + 8,6 + 10,7 Inland + 15,5 + 18,6 Ausland - 2,7 - 2,1 Grundstoff- und Produktionsgütergewerbe + 5,4 + 4,6 Investitionsgüter produzierendes Gewerbe + 9,1 + 12,4 Verbrauchsgüter produzierendes Gewerbe + 11,3 + 14,3'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_par.iloc[0]['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankfurt Lebenshaltung zwei und Schluß Lebenshaltung zwei und Schluß Autofahrer zur Kasse gebeten. Weit über der allgemeinen Teuerungsrate war der Preisauftrieb «rund ums Auto». Der sogenannte Kraftfahrerpreisindex lag im Dezember um 4,5 Prozent über dem Stand des Vorjahres. In diesem Teilindex erfassen die Wiesbadener Statistiker die Preise für Neuwagen, Reparaturen sowie Versicherungsprämien und Spritkosten. Dabei hat es von November bis Dezember sogar noch einen Rückgang des Kraftfahrerindex von 1,1 Prozent parallel zu den sinkenden Benzinpreisen gegeben. Lebenshaltungspreise Veränderung zu Neuer Dezember Vorjahr Vormonat Indexstand (1985: 100) Gesamtindex + 2,8 + 0,1 108,1 Ohne Saisonwaren + 2,7 - 0,1 Teilindex für Nahrungsmittel + 2,1 + 0,5 Teilindex für Dienstleistungen und Reparaturen + 2,3 + 0,2 Teilindex Mieten und Garagen + 3,8 + 0,3 4-Personen-Arbeitnehmer-Haushalt mit mittlerem Einkommen + 2,8 0,0 107,8 4-Personen-Arbeitnehmer-Haushalt mit höherem Einkommen + 2,5 0,0 108,6 2-Personen-Haushalte von Renten- und Sozialhilfeempfängern + 2,7 + 0,2 108,0 Einzelhandelspreise + 2,2 + 0,1 124,9 Kraftfahrer-Preisindex + 4,5 - 1,1 109,3'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant_par.iloc[1]['texts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in quant_par[:20].iterrows():\n",
    "#    print(index, row['texts'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_table = data[data.texts.str.contains(r'Im einzelnen kam es zu folgenden Veränderungen.{0,}')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in re_table.iterrows():\n",
    "#    print(index, row['texts'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in re_table.iterrows():\n",
    "#    print(index, re.findall(r'Im einzelnen ergaben sich folgende Veränderungen.{0,}', row['texts']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in re_table.iterrows():\n",
    "#    if index in quant_par.index:\n",
    "#        print(index, re.findall(r'Im einzelnen kam es zu folgenden Veränderungen.{0,}', row['texts']), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub(r'Weltautomobilproduktion \\(in Millionen Wagen\\).{0,}', '', quant_par.iloc[6]['texts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean tables using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    remove_tables = pool.map(clean_tables.clean_tables, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)\n",
    "\n",
    "data['texts'] = remove_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    count_results = pool.map(count_words_mp.count_words_mp, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result as a new column \"word_count\"\n",
    "data['word_count'] = count_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove articles with less than 100 words\n",
    "data = data[data['word_count']>=100]\n",
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))\n",
    "del data['numeric_par']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge continuations of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dpa-afx articles are split into multiple entries marked by the word 'Fortsetzung' at the beginning of the texts of following entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRANKFURT (dpa-AFX) - Der deutsche Aktienmarkt hat am Montag für wenige Augenblicke seinen Rekordschluss vom Juli 1998 überschritten. Mit einem Höchststand von 6.188,68 lag der Dax über dem Tageschluss vom 21. Juli 1998, als der Index 6.186 Punkte erreichte. Der Dax <DAX.ETR> schloss den Handel am ersten Wochentag bei 6.142,19 Zählern und damit um 0,38% oder 23,02 Punkte fester ab. Der Nebenwerteindex M-Dax <MDAX.ETR> gab dagegen auf 3.990,00 Punkte oder um 1,43% nach, und der Neue Markt-Index Nemax 50 <NMKX.ETR> schloss bei 4.610,66 Zählern (-0,58%).      Spätestens auf dem Niveau des All-Time-High bei ungefähr 6.200 Punkten werde der Index auf einen massiven Widerstand stoßen, heißt es am Montag in einem Research-Report von der Nürnberger Schmidt Bank. Michael Schubert, Analyst der Bankgesellschaft Berlin, sagte in einem Gespräch mit dpa-AFX, derzeit sei der einzig negative Faktor, dass die Börse nicht von der Breite getragen werde, sondern nur von wenigen Titeln. Wer jetzt noch nicht investiert habe, sei in einer unangenehmen Situation: Er müsse dem Markt hinterherlaufen. Nach Meinung von Schubert ist eine Konsolidierung bis auf einen Wert von 6.000 oder 5.800 Zähler durchaus sinnvoll. Der Rückschritt soll sich am Besten ein bis zwei Wochen hinziehen, sagte Schubert./mr/ba'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texts'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Fortsetzung) - Der Tagesgewinner SAP <SAP.ETR> übernahm bereits am Vormittag die Führung bei den Gewinnern ein und schloss den Handel mit einem Kurszuwachs von 6,27% auf 475,20 Euro ab. Händler waren sich einig darüber, dass SAP weiteres Wachstumpotenzial haben. Ende vergangener Woche habe es Kaufempfehlungen für das Papier gegeben, sagte ein Händler. Die ABN Amro Bank hatte ihr Kursziel mit 600 Euro festgesetzt.      Den Wert umgaben zudem Gerüchte über eine bevorstehende Allianz mit einem Weltkonzern, hieß es. Ein anderer Händler hielt den aktuellen SAP-Kurs noch immer für zu billig. Wachstumswerte stünden weiter in der Gunst der Anleger. Bei SAP hätten Image und Aktienkurs unter Problemen in den USA gelitten. Das werde nach Erwartung des Händlers aber spätestens mit den Geschäftszahlen des ersten Quartals 2000 überwunden sein. Mit dem Ende der Angst vor dem Jahr-2000-Problem würde der Kurs weiter steigen.     Ihren Kurshöhenflug fortsetzen konnten zudem die Aktien von Siemens <SIE.ETR>. Sie schlossen den Handel um 4,94% fester bei 114,70 Euro. Der Technologiekonzern hatte am Vormittag bekannt gegeben, dass das Unternehmen seinen Atombereich mit der französischen Framatome zusammenlegen will. An dem Joint Venture soll Framatome 66%, Siemens wird 34% der Anteile halten. Für Alexander Koch von der KBC Bank Deutschland unterstützt diese Meldung den positiven Trend bei Siemens. Das ist jener Dax-Wert, der charttechnisch zur Zeit am besten aussieht, sagte er.     Die Aktie der Mannesmann AG <MMN.ETR> hat sich nach einer Klage der Mannesmann-Aktionäre gegen das eigene Management am Montag ebenfalls fest präsentiert. Der Titel schloss bei einem Kurs von 235,00 Euro und damit 4,44% fester. Gegen die Werbekampagne von Mannesmann bei Anlegern und Investoren, mit der eine Übernahmen durch Vodafone Airtouch <VOD.ISS> verhindert werden soll, sind inzwischen einige Aktionäre gerichtlich vorgegangen.(...)/mr/fs'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texts'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Fortsetzung) - Überraschend fest tendierten am Montag die Autowerte. Volkswagen <VOW.ETR> gewannen 1,6% auf 49,35 Euro. Vielleicht sehen wir jetzt tatsächlich eine Branchen-Rotation zur Autobranche hin, sagte ein Händler der DG-Bank. Die nahe Zukunft des Wertes stehe oder falle mit der 50 Euro Marke. Auch BMW <BMW.ETR> (28,10 Euro/+1,04%) und DaimlerChrysler <DCX.ETR> (67,25 Euro/+0,67%)  verbuchten Kurszuwächse. Alle drei deutschen Hersteller verbuchten einem Pressebericht zufolge im Gesamtjahr 1999 steigende Absatzzahlen in den USA.       Die Verliererliste führten am Montag Lufthansa <LHA.ETR> (22,30 Euro/-3,88%) und Veba <VEB.ETR> (45,47 Euro/-3,87%) an. Unter Gewinnmitnahmen litt laut Händlern der Kurs der T-Aktie <DTE.ETR>: Der Titel verlor im Montagshandel 1,31% auf 59,30 Euro. Wäre die Telekom mit dem Indextrend im Wert gestiegen, hätte der Dax den Rekordstand vom Juli 1998 eingestellt, rechnete ein Händler am Nachmittag vor./mr/fs'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texts'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify which entries belong together and merge them to one article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into roughly equal sized chunks where articles from one day only fall under the same chunk\n",
    "data_cont = data[data['topic'] == 'afx']\n",
    "dates = data_cont.groupby(['year', 'month', 'day'])\n",
    "dates = list(dates.groups)\n",
    "dates = np.array_split(dates, NUM_CORE)\n",
    "\n",
    "meta_data = data_cont.loc[:, data_cont.columns != 'texts']\n",
    "\n",
    "chunks = [pd.concat([data_cont[(data_cont['year'] == t[0]) & (data_cont['month'] == t[1]) & (data_cont['day'] == t[2])] for t in tup]) for tup in dates]\n",
    "chunks = [[chunk, meta_data] for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:14:56.636717\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    continue_results = pool.map(continue_articles.continue_articles, chunks) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(list(itertools.chain(*[tup[0] for tup in continue_results])), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_articles = pd.concat([tup[1] for tup in continue_results])\n",
    "print(len(continue_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974426\n"
     ]
    }
   ],
   "source": [
    "data = data.append(continue_articles)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:06:33.551105\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    url_corrected = pool.map(correct_url.correct_url, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = url_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove dpa references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove dpa references (e.g. NEW YORK (dpa) - ...) from each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:15:15.393896\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    dpa_ref_removed = pool.map(clean_dpa_references.clean_dpa_references, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = dpa_ref_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step11.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umlauts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older articles (1991 - 2000) from the section 'Kommentar' (Commentary) are often missing umlauts and correct capitalization. To\n",
    "fix these two issues, we use the notebook Umlauts_fix written in Python 2 and the notebook Truecasing written in Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "umlauts = ['ä', 'ö', 'ü', 'ß', 'Ä', 'Ö', 'Ü']\n",
    "umlauts_replace = ['ae', 'oe', 'ue', 'ss', 'AE', 'OE', 'UE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_umlauts_fix = data[(data.texts.str.contains('|'.join(umlauts_replace))) & (~data.texts.str.contains('|'.join(umlauts))) & (data.year<2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ad-hoc announcement sent by DGAP. The sender is solely responsible for the contents of this announcement.  Ad-hoc Mitteilung Nach @ 15 WpHG  WizCom Technologies Ltd. (WizCom) <WZM.FSE> (Neuer Markt:WZM,WKN:915 856) veroeffentlicht das Ergebnis fuer das am 31. Dezember 1999 endende Geschaeftsjahr 20. Maerz 2000, Jerusalem, Israel - Der Umsatz belief sich im Jahr 1999 auf US$ Mio. 11,613. Der Vorjahreswert lag bei US$ Mio. 15,799. Der Umsatz im ersten bzw. zweiten Halbjahr 1999 betrug US$ Mio. 4,046 bzw. US$ Mio. 7,567. Das Unternehmen sieht den Umsatzrueckgang als voruebergehend an und vor allem im zweiten Halbjahr begruendet, weil das neue Produkt, der QuickLink-Pen, erst mit einigen Monaten Verzoegerung auf den Markt gebracht werden konnte. Im 4. Quartal 1999 konnte WizCom den QuickLink Pen in den USA erfolgreich auf den Markt bringen. Im 1. Quartal 2000 vermarktet WizCom den QuickLink Pen in weiteren Laendern, unter anderem Australien, Grossbritannien, Deutschland und Frankreich. Der Bruttogewinn verringerte sich von US$ Mio. 5,503 im Jahr 1998 auf US$ Mio. 3,221 im Jahr 1999. Dies ist hauptsaechlich auf den voruebergehenden Rueckgang beim Umsatz und auf die Fixkosten fuer das neue Produkt, den QuickLink-Pen, zurueckzufuehren. Der Nettoverlust fuer das Jahr 1999 betrug US$ Mio. 11,692, gegenueber US$ Mio. 4,130 in 1998. Hierin enthalten ist die einmalige Rueckzahlung eines Disagios auf Wandel-schuldverschreibungen in Hoehe von US$ Mio. 4,659 sowie eine Abschreibung auf  laufende Forschungs- und Entwicklungsarbeiten in Hoehe von US$ Mio. 2,271. WizCom ist ein Weltmarktfuehrer im Bereich der tragbaren Datenerfassungstechnologien. WizCom produziert und vermarktet die Produkte der Quicktionary Produktfamilie - tragbare stiftfoermige Scanner fuer den Linguistik- und Lehrmitttelmarkt. WizCom verfuegt ueber die einzigartige OCR (Optical Character Resolution)- Technologie, die in den Produkten implementiert sind. Seit Januar 2000 hat Wizcom seine Produktreihe um die erste Generation der Quicktionary Produkte, das Quicktionary II und den QuickLink-Pen, erweitert. Wizcom erwartet ein deutliches Umsatzwachstum sowohl im ersten Quartal 2000, als auch fuer den Rest des Jahres. Die Umsatzsteigerung wird zum einen auf dem Verkauf des QuickLink-Pen in den USA und weltweit basieren, zum anderen auf der Vermarktung des Quicktionary II nach der erwarteten Markteinfuehrung im 2. Quartal 2000. Zusaetzliche Einnahmen wird der Verkauf der Wizcom Plug- ins fuer Mobiltelefone im 4. Quartal bringen. Vor Kurzem hat Wizcom ein Lizenzabkommen mit Ericsson angekuendigt. Dieses Abkommen ermoeglicht es Wizcom, Technologie von Ericsson bei der Entwicklung von Plug-ins fuer Mobiltelefone von Ericsson zu verwenden. Mit diesen Plug-ins koennen Besitzer von Mobiltelefonen auf Papier vorliegenden Text direkt in ihr Mobiltelefon einscannen und so Daten speichern, via WAP dem Internet zur Verfuegung stellen oder per SMS versenden. Weitere Anwendungen werden entwickelt. Dieses Abkommen ist ein weiterer Schritt auf Wizcoms Weg zur Marktfuehrung im Sektor der tragbaren Datenlesegeraete und zur weiteren Verbreitung seiner Scann- und Texterkennungstechnologien im Marktsegment der tragbaren Geraete. Nach dem Abkommen mit Ericsson haben auch andere namhafte Hersteller und Serviceanbieter mit Wizcom Kontakt aufgenommen, um Wege fuer den Einsatz dieser innovativen Technologie zu finden.  Ende der Mitteilung'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa_umlauts_fix['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_umlauts_fix.to_csv('dpa_umlauts_fix.csv', encoding='utf-8-sig', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_umlauts_fixed = pd.read_csv('dpa_umlauts_fixed.csv', encoding = 'utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step12.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truecasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_cases_fix = data[data.texts.str.contains('^(?!.*[A-Z])')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new york (vwd) - enttaeuschend verlief das geschaeft am mittwoch, dem ersten handelstag im neuen jahr, an der new yorker aktienboerse. die zunaechst gesehenen leichten gewinne konnten nur bis in das fruehe nachmittagsgeschaeft behauptet werden. in den letzten 2-1/2 geschaeftststunden gerieten die kurse in die minuszone und wall street schloss auf breiter front schwaecher. der dow-jones-index fuer 30 industriewerte gab um 23,02 auf 2.610,64 punkte nach. auch die uebrigen marktbestimmenden indizes gerieten in die minuszone. bei einem umsatz von 126,28 (114,13) millionen aktien standen die kursverlierer den -gewinnern im verhaeltnis von rund neun zu sieben gegenueber. verantwortlich fuer die schwaeche waren wiederauflebende befuerchtungen ueber eine anhaltende rezessionsphase. nachdem sogar das weisse haus jetzt von einer rezessionaeren entwicklung spricht, hielten sich die meisten anleger mit ihren engagements zurueck, wodurch der vorherrschende abgabedruck ausreichte, um die kurse in die minuszone zu treiben. vor allem neue konjunktureckdaten, die auf eine rezession hindeuten, standen hinter der abwaertsbewegung. bei vielen anlegern setzte sich die befuerchtung durch, dass die schwache konjunktur zu einer schmaelerung der unternehmensertraege fuehren werde. vwd/2.1.91/06/mp/hs'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa_cases_fix['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_cases_fix.to_csv('dpa_case_fix.csv', encoding='utf-8-sig', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_cases_fixed = pd.read_csv('dpa_cases_fixed.csv', encoding = 'utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[dpa_cases_fixed.index, 'texts'] = dpa_cases_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York( Vwd)- Enttaeuschend verlief das Geschaeft am Mittwoch, dem ersten Handelstag im neuen Jahr, an der New Yorker Aktienboerse. Die Zunaechst Gesehenen leichten Gewinne konnten nur bis in das Fruehe Nachmittagsgeschaeft behauptet werden. In den letzten 2-1/2 Geschaeftststunden gerieten die Kurse in die Minuszone und Wall Street schloss auf breiter Front Schwaecher. Der Dow-Jones-Index Fuer 30 Industriewerte gab um 23,02 auf 2.610,64 Punkte nach. Auch die Uebrigen Marktbestimmenden Indizes gerieten in die Minuszone. Bei einem Umsatz von 126,28( 114,13) Millionen Aktien standen die Kursverlierer den -Gewinnern im Verhaeltnis von rund neun zu sieben Gegenueber. Verantwortlich Fuer die Schwaeche waren Wiederauflebende Befuerchtungen Ueber eine anhaltende Rezessionsphase. Nachdem sogar das Weisse Haus jetzt von einer Rezessionaeren Entwicklung spricht, hielten sich die meisten Anleger mit ihren Engagements Zurueck, wodurch der vorherrschende Abgabedruck ausreichte, um die Kurse in die Minuszone zu treiben. Vor allem neue Konjunktureckdaten, die auf eine Rezession hindeuten, standen hinter der Abwaertsbewegung. Bei vielen Anlegern setzte sich die Befuerchtung durch, dass die schwache Konjunktur zu einer Schmaelerung der Unternehmensertraege Fuehren werde. Vwd/2.1.91/06/Mp/Hs'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixed version\n",
    "data['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step13.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing tokens containing a number and a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In quite a few cases, a number and a word are erroneously merged into a single token. Splitting these tokens into two tokens helps us to deal with the following problems:\n",
    "\n",
    "(see Handelsblatt notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:13.158789\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "import split_number_word\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    split_corrected = pool.map(split_number_word.split_number_word, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = split_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step14.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Fuzzy Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_keep = ['russische Aktienmarkt', 'europäischen Börsen', 'Deutsche Börse' ,'Europäische Zentralbank',\n",
    "'Moskauer Aktienmarkt', 'deutsche Aktienmarkt', 'deutschen Aktienmarkt', 'Folgende Investmentbanken',\n",
    "'deutsche Rentenmarkt', 'amerikanischen Treasury Bonds', 'IRW-PRESS', 'Deutsche Bank', 'Ausgewählte Analysten-Einstufungen',\n",
    "'Deutsche Staatsanleihen', 'Der japanische Aktienmarkt']\n",
    "\n",
    "exceptions = ['NO_EXCEPTIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991.0\n",
      "1992.0\n",
      "1993.0\n",
      "1994.0\n",
      "1995.0\n",
      "1996.0\n",
      "1997.0\n",
      "1998.0\n",
      "1999.0\n",
      "2000.0\n",
      "2001.0\n",
      "2002.0\n",
      "2003.0\n",
      "2004.0\n",
      "2005.0\n",
      "2006.0\n",
      "2007.0\n",
      "2008.0\n",
      "2009.0\n",
      "2010.0\n",
      "2011.0\n",
      "2012.0\n",
      "2013.0\n",
      "2014.0\n",
      "2015.0\n",
      "2016.0\n",
      "2017.0\n",
      "2018.0\n",
      "6:58:11.847691\n"
     ]
    }
   ],
   "source": [
    "# import a function that outputs the indices of duplicates \n",
    "import fuzzy_duplicates\n",
    "delete_indices = []\n",
    "startTime = datetime.now() \n",
    "for year in list(set(data['year'])):\n",
    "    data_input = data[(data['year'] == year)]\n",
    "    for month in list(set(data_input[data_input['year'] == year]['month'])): # old: list(set(data))\n",
    "            # Prepare inputs\n",
    "            inputs_year = []\n",
    "            inputs_month = []\n",
    "            inputs_month_year = []\n",
    "            inputs_year.append(year)\n",
    "            inputs_month.append(month)\n",
    "            inputs_month_year.append(data_input[(data_input['year'] == year) & (data_input['month'] == month)][[\"month\", \"year\", \"texts\"]])\n",
    "\n",
    "            #from itertools import repeat\n",
    "            inputs = list(zip(inputs_year, inputs_month, inputs_month_year))\n",
    "            from datetime import datetime\n",
    "            if __name__ == \"__main__\":\n",
    "                pool = mp.Pool(NUM_CORE)\n",
    "                # apply function to all combinations of month-year in parallel\n",
    "                delete_intermediate = pool.starmap(fuzzy_duplicates.fuzzy_duplicates, zip(inputs, repeat(types_keep), repeat(exceptions)))\n",
    "                delete_indices = delete_indices + delete_intermediate # create one list of indices\n",
    "                pool.close()\n",
    "                pool.join()  \n",
    "    print(year)\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_indices = list(set([item for sublist in delete_indices for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580324\n"
     ]
    }
   ],
   "source": [
    "data.drop(delete_indices, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step15.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dpa articles include some unnecessary text passages like inquiry notes or references to webpages. We decided to clean the \n",
    "affected articles from these text passages to make the sentiment classification easier for our model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the following terms and sections from the texts:\n",
    "* 1) stock symbols\n",
    "* 2) additional metadata in the text meant for the author\n",
    "* 3) references to previos articles\n",
    "* 4) references to dpa and dpa-AFX webpage\n",
    "* 5) uncorrected original article on which a correction is based on\n",
    "* 6) inquiry notes\n",
    "* 7) reference to english article on which some articles are based on\n",
    "* 8) date of the article\n",
    "* 9) references for aditional information (phone numbers, webpages etc.)\n",
    "* 10) references to sender\n",
    "* 11) references to Debitos\n",
    "* 12) references to issuer\n",
    "* 13) reference to authors\n",
    "* 14) references to summary of article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:58:52.745164\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    cleaned_articles = pool.map(clean_dpa_articles.clean_dpa_articles, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = cleaned_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
