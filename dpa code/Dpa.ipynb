{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools\n",
    "import dpa_load\n",
    "import multiprocessing as mp\n",
    "from datetime import datetime\n",
    "from itertools import repeat\n",
    "import split_articles\n",
    "import numeric_articles\n",
    "import continue_articles\n",
    "# we import some functions from the Handelsblatt folder\n",
    "import sys\n",
    "sys.path.insert(1, os.getcwd().replace('dpa code', 'Handelsblatt'))\n",
    "import count_words_mp\n",
    "import identify_eng_2\n",
    "import correct_url\n",
    "import clean_dpa_articles\n",
    "import clean_dpa_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of cores to use\n",
    "NUM_CORE = mp.cpu_count()-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPA Data (1991 - 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deutsche PresseAgentur (DPA) is the Germany's biggest news agency which sells its news reports to the leading German newspapers. We believe that the data set has a high chance to be useful for economic forecasting because DPA produces information that is timely and has a large reach.\n",
    "\n",
    "We purchased DPA data in November 2019. The corpus consists of **7,539,874** articles from January 1991 to December 2018.\n",
    "\n",
    "The data set includes news from both dpa-Basisdienstes and dpa-afx Wirtschaftsnachrichten. The former one is the basic news service covering such topics as Economy, Politics, and  Finance. The second one was created in 1999. It specializes in financial news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read in the data by extracting the following XML elements:\n",
    "\n",
    "* title - article's title\n",
    "* text - text of the article\n",
    "* date - publication date\n",
    "* ressort - section (Politics vs Economy)\n",
    "* source/credit - source (dpa vs afx)\n",
    "* city - which city the news article refers to\n",
    "* genre - journalistic genre, e.g., chronology, story, table\n",
    "* wortanzahl - word count\n",
    "* keywords - keywords associated with an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder with unpacked articles\n",
    "#path = r'E:\\\\Userhome\\\\jbaer\\\\dpa_unpacked'\n",
    "\n",
    "#path = r'G:\\\\Test\\\\Results\\\\dpa Raw Data\\\\dpa_unpacked'\n",
    "path = os.getcwd().replace('\\\\newspaper_data_processing\\\\dpa code', '') + '\\\\dpa_unpacked'\n",
    "\n",
    "folder_list = []\n",
    "\n",
    "# 2 folders for dpa and dpa-afx \n",
    "for fol in [fol for fol in os.listdir(path)]:\n",
    "\n",
    "    # Within each folder: folders for different years\n",
    "    for f in [f for f in os.listdir(path + '\\\\' + fol)]:\n",
    "        folder_list.append(path + '\\\\' + fol + '\\\\' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a path to the folder for storing results\n",
    "#PATH = r'G:\\\\Test\\\\Results'\n",
    "#os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:25:04.926592\n"
     ]
    }
   ],
   "source": [
    "# Use the 'dpa_load' function to load articles\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    df_list = pool.map(dpa_load.dpa_load, folder_list)\n",
    "    data = pd.concat(df_list)\n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7539874\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>file</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>source</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>genre</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hessischer Energieversorger EAM senkt Strompre...</td>\n",
       "      <td>16147043.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1999</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa-afx</td>\n",
       "      <td>PRD</td>\n",
       "      <td>Hessischer Energieversorger EAM senkt Strompre...</td>\n",
       "      <td>KASSEL</td>\n",
       "      <td></td>\n",
       "      <td>127</td>\n",
       "      <td>afx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Europäische Bonds: Bei dünnem Handel leichter....</td>\n",
       "      <td>16147044.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1999</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa-afx</td>\n",
       "      <td>BND CLO</td>\n",
       "      <td>Europäische Bonds: Bei dünnem Handel leichter.</td>\n",
       "      <td>LONDON</td>\n",
       "      <td></td>\n",
       "      <td>110</td>\n",
       "      <td>afx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US-Paketzusteller UPS stellt für Steuerstreit ...</td>\n",
       "      <td>16147045.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1999</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa-afx</td>\n",
       "      <td>FNG</td>\n",
       "      <td>US-Paketzusteller UPS stellt für Steuerstreit ...</td>\n",
       "      <td>ATLANTA</td>\n",
       "      <td></td>\n",
       "      <td>131</td>\n",
       "      <td>afx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Burlington kauft kanadische Erdgasfirma für 2,...</td>\n",
       "      <td>16147046.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1999</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa-afx</td>\n",
       "      <td>MNA</td>\n",
       "      <td>Burlington kauft kanadische Erdgasfirma für 2,...</td>\n",
       "      <td>HOUSTON</td>\n",
       "      <td></td>\n",
       "      <td>68</td>\n",
       "      <td>afx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNP bewertet Consors nach Halbjahresergebnis w...</td>\n",
       "      <td>16147047.xml</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>1999</td>\n",
       "      <td>wi</td>\n",
       "      <td>dpa-afx</td>\n",
       "      <td>RTG</td>\n",
       "      <td>BNP bewertet Consors nach Halbjahresergebnis w...</td>\n",
       "      <td>FRANKFURT</td>\n",
       "      <td></td>\n",
       "      <td>97</td>\n",
       "      <td>afx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts          file  day  \\\n",
       "0  Hessischer Energieversorger EAM senkt Strompre...  16147043.xml   17   \n",
       "1  Europäische Bonds: Bei dünnem Handel leichter....  16147044.xml   17   \n",
       "2  US-Paketzusteller UPS stellt für Steuerstreit ...  16147045.xml   17   \n",
       "3  Burlington kauft kanadische Erdgasfirma für 2,...  16147046.xml   17   \n",
       "4  BNP bewertet Consors nach Halbjahresergebnis w...  16147047.xml   17   \n",
       "\n",
       "   month  year rubrics   source keywords  \\\n",
       "0      8  1999      wi  dpa-afx      PRD   \n",
       "1      8  1999      wi  dpa-afx  BND CLO   \n",
       "2      8  1999      wi  dpa-afx      FNG   \n",
       "3      8  1999      wi  dpa-afx      MNA   \n",
       "4      8  1999      wi  dpa-afx      RTG   \n",
       "\n",
       "                                               title       city genre  \\\n",
       "0  Hessischer Energieversorger EAM senkt Strompre...     KASSEL         \n",
       "1     Europäische Bonds: Bei dünnem Handel leichter.     LONDON         \n",
       "2  US-Paketzusteller UPS stellt für Steuerstreit ...    ATLANTA         \n",
       "3  Burlington kauft kanadische Erdgasfirma für 2,...    HOUSTON         \n",
       "4  BNP bewertet Consors nach Halbjahresergebnis w...  FRANKFURT         \n",
       "\n",
       "  wordcount topic  \n",
       "0       127   afx  \n",
       "1       110   afx  \n",
       "2       131   afx  \n",
       "3        68   afx  \n",
       "4        97   afx  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dpa_raw.csv', encoding = 'utf-8', index_col = 0,  keep_default_na=False,\n",
    "                   dtype = {'rubrics': 'str', \n",
    "                            'source': 'str',\n",
    "                            'keywords': 'str',\n",
    "                            'title': 'str',\n",
    "                            'city': 'str',\n",
    "                            'genre': 'str',\n",
    "                            'wordcount': 'str'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_values(['year', 'month', 'day'], ascending=[True, True, True]) # sort the data in chronological order\n",
    "data.reset_index(inplace=True, drop=True) # reset the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>file</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>rubrics</th>\n",
       "      <th>source</th>\n",
       "      <th>keywords</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>genre</th>\n",
       "      <th>wordcount</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Schalck: Milliardenkredit sicherte Zahlungsfäh...</td>\n",
       "      <td>5739189.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Schalck-Golodkowski</td>\n",
       "      <td>Schalck: Milliardenkredit sicherte Zahlungsfäh...</td>\n",
       "      <td>Berlin</td>\n",
       "      <td></td>\n",
       "      <td>218</td>\n",
       "      <td>WiPo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tschads Regierung: Bevölkerung soll Waffen abl...</td>\n",
       "      <td>5739191.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Tschad</td>\n",
       "      <td>Tschads Regierung: Bevölkerung soll Waffen abl...</td>\n",
       "      <td>N'Djamena</td>\n",
       "      <td></td>\n",
       "      <td>75</td>\n",
       "      <td>WiPo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Welajati: Iran bleibt bei einem Krieg am Golf ...</td>\n",
       "      <td>5739193.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise Iran</td>\n",
       "      <td>Welajati: Iran bleibt bei einem Krieg am Golf ...</td>\n",
       "      <td>Teheran</td>\n",
       "      <td></td>\n",
       "      <td>90</td>\n",
       "      <td>WiPo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bush will offenbar seinen Außenminister erneut...</td>\n",
       "      <td>5739195.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise USA</td>\n",
       "      <td>Bush will offenbar seinen Außenminister erneut...</td>\n",
       "      <td>Washington</td>\n",
       "      <td></td>\n",
       "      <td>181</td>\n",
       "      <td>WiPo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Morgenzusammenfassung Neue Runde diplomatische...</td>\n",
       "      <td>5739199.xml</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1991</td>\n",
       "      <td>pl</td>\n",
       "      <td>dpa</td>\n",
       "      <td>Golfkrise</td>\n",
       "      <td>Morgenzusammenfassung Neue Runde diplomatische...</td>\n",
       "      <td>Washington/Luxemburg</td>\n",
       "      <td></td>\n",
       "      <td>504</td>\n",
       "      <td>WiPo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts         file  day  month  \\\n",
       "0  Schalck: Milliardenkredit sicherte Zahlungsfäh...  5739189.xml    1      1   \n",
       "1  Tschads Regierung: Bevölkerung soll Waffen abl...  5739191.xml    1      1   \n",
       "2  Welajati: Iran bleibt bei einem Krieg am Golf ...  5739193.xml    1      1   \n",
       "3  Bush will offenbar seinen Außenminister erneut...  5739195.xml    1      1   \n",
       "4  Morgenzusammenfassung Neue Runde diplomatische...  5739199.xml    1      1   \n",
       "\n",
       "   year rubrics source             keywords  \\\n",
       "0  1991      pl    dpa  Schalck-Golodkowski   \n",
       "1  1991      pl    dpa               Tschad   \n",
       "2  1991      pl    dpa       Golfkrise Iran   \n",
       "3  1991      pl    dpa        Golfkrise USA   \n",
       "4  1991      pl    dpa            Golfkrise   \n",
       "\n",
       "                                               title                  city  \\\n",
       "0  Schalck: Milliardenkredit sicherte Zahlungsfäh...                Berlin   \n",
       "1  Tschads Regierung: Bevölkerung soll Waffen abl...             N'Djamena   \n",
       "2  Welajati: Iran bleibt bei einem Krieg am Golf ...               Teheran   \n",
       "3  Bush will offenbar seinen Außenminister erneut...            Washington   \n",
       "4  Morgenzusammenfassung Neue Runde diplomatische...  Washington/Luxemburg   \n",
       "\n",
       "  genre wordcount topic  \n",
       "0             218  WiPo  \n",
       "1              75  WiPo  \n",
       "2              90  WiPo  \n",
       "3             181  WiPo  \n",
       "4             504  WiPo  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove short articles (<100 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short articles are often incoherent or contain only insiginicant news. For this reason we decided to filter out articles that consist of less than 100 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:34.731927\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    count_results = pool.map(count_words_mp.count_words_mp, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result as a new column \"word_count\"\n",
    "data['word_count'] = count_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5366317\n"
     ]
    }
   ],
   "source": [
    "# remove articles with less than 100 words\n",
    "data = data[data['word_count']>=100]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove exact duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some articles are more than once in the corpus. We filter out all duplicates and only keep the articles with the oldest date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4542012\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(['texts'], keep = 'first', inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, dpa articles are not as consistently sorted into sections and subsections as articles from other \n",
    "news media. Instead, we investigate the most commonly used titles and keywords and remove non-economic articles based on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude non-economic and other irrelevant articles based on the following titles\n",
    "\n",
    "* 1) Londoner Edelmetallpreise: Precious metal prices (without text)\n",
    "* 2) Tageskalender: List of upcoming events\n",
    "* 3) (Tabelle): Tables in text form\n",
    "* 4) SPORT, Sport (except for the titles that contain TRANSPORT, INTERSPORT, PASSPORT, Sportartikel, news about sportswear manufacturers, sporting goods industry, SPORTARTIKLER, Sportmodelle, or Sportswear): news related to Sports. Beware that news about sports marketing agencies (e.g., Sportfive), sports media websites (e.g., Sportal), and new sports models of car manufacturers might be removed as well. \n",
    "* 5) Berichtigung, KORREKTUR (except for the titles that contain Berichtigungsaktien, rectified shares): Article corrections\n",
    "* 6) Impressum: Dpa contact data\n",
    "* 7) Testmeldung: Test-articles from dpa\n",
    "* 8) Kurse A, Kurse B, Kurse C, Kurse D, KURSE A, KURSE B, KURSE C, KURSE DREI, KURSE Drei, Kurse drei: Stock charts without text\n",
    "* 9) DGAP-DD: DGAP reports\n",
    "* 10) New Yorker Aktien-Schlußkurse: Stock closing prices at the New York stock exchange (articles only occur from 1997 to 2002)\n",
    "* 11) VERMISCHTES: Miscellaneous with no relation to economics\n",
    "* 12) Angekündigte US-Quartalszahlen auf einen Blick: Quarterly US figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4207086\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-economic articles based on titles.\n",
    "fil_titles = '''Londoner Edelmetallpreise|Tageskalender|\\(Tabelle\\)|SPORT|Sport|Berichtigung|KORREKTUR|Impressum|Testmeldung|Kurse A[^a-z]|Kurse B[^a-z]|Kurse C[^a-z]|Kurse D[^a-z]|KURSE A|KURSE B|KURSE C|KURSE DREI|Kurse drei|KURSE Drei|Kurse/drei|DGAP-DD|New Yorker Aktien-Schlusskurse|VERMISCHTES|Angekündigte US-Quartalszahlen'''\n",
    "titles_exc = '''TRANSPORT|INTERSPORT|PASSPORT|Berichtigungsaktien|Sportartikel|SPORTARTIKLER|Sportmodelle|Sportswear'''\n",
    "data.drop(data[(data['title'].str.contains(fil_titles, na = False)) & (~data['title'].str.contains(titles_exc, na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude non-economic articles based on the following sections.\n",
    "\n",
    "* 1) Tabelle: Tables in text form (some articles are still left after the previos step)\n",
    "* 2) Historisches: News about historical events\n",
    "* 3) Achtung: Announcemt of upcoming news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4183903\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-economic articles based on sections.\n",
    "fil_genres = '''Tabelle|Historisches|Achtung'''\n",
    "data.drop(data[data['genre'].str.contains(fil_genres, na = False)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude non-economic articles based on the following keywords.\n",
    "* 1) Redaktionshinweis: Editor's notes for Dpa journalists\n",
    "* 2) DGAP: DGAP reports\n",
    "* 3) Sport, SPORT, SPO (except for Sportartikel, this section contains articles on sports companies): Sport news (some sports articles are still left after the previos steps)\n",
    "* 4) Kurse A, Kurse B, Kurse C, Kurse D, KURSE A, KURSE B, KURSE C, Kurse D,\n",
    "     KURSE DREI, Kurse drei, KURSE Drei, KURSE drei, Kurse Drei, Kurse/drei: Stock charts without text (some articles are  still left after the previos steps)\n",
    "* 5) Tagesvorschau, Vorschau, VORSCHAU, vorschau: List of titles of upcoming news\n",
    "* 6) Bilderdienst: Dpa Picture Service\n",
    "* 7) Geschichte: News related to historical events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3926157\n"
     ]
    }
   ],
   "source": [
    "# Filter out non-economic articles based on keywords.\n",
    "fil_keywords = '''Redaktionshinweis|DGAP|Sport|SPORT|SPO|Kurse A|Kurse B|Kurse C|Kurse D|KURSE A|KURSE B|KURSE C|KURSE DREI|Kurse drei|KURSE Drei|KURSE drei|Kurse Drei|Kurse/drei|Kurse D|Tagesvorschau|Vorschau|vorschau|VORSCHAU|Bilderdienst|Geschichte'''\n",
    "keywords_exc = '''Sportartikel'''\n",
    "data.drop(data[(data['keywords'].str.contains(fil_keywords, na = False)) & (~data['keywords'].str.contains(keywords_exc, na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude articles based on the following bits of text.\n",
    "* 1) Schalterverkaufskurse: Precios metal prices\n",
    "* 2) dpa-news.de: News regarding the Dpa website\n",
    "* 3) Wirtschafts- und Finanztermine, Wirtschafts- und Finanz-Termine, Konjunktur- und Wirtschaftstermine: List of dates when economic data will be published/economic events will take place\n",
    "* 4) DGAP (except for articles that contain DGAP standing for Deutsche Gesellschaft für Auswärtige Politik): DGAP reports\n",
    "* 5) Bitte verwenden Sie diese Meldung nicht: Retracted articles\n",
    "* 6) \\( Wiederholung: Repeated articles\n",
    "* 7) [§] 26 Abs., § 15a WpHG 1, § 15 WpHG, Artikel 19 MAR, article 19 Market Abuse Regulation (MAR): Regulatory news\n",
    "* 8) Die Pivotpunkte für den Dax-Future: Pivot points for the Dax-Future\n",
    "* 9) An der Frankfurter Wertpapierbörse wurden, Die Aktien im Dow Jones EuroStoxx 50, Die Aktien im Dow Jones Euro Stoxx 50: Stock charts\n",
    "* 10) Ihr Ansprechpartner: Redaktion Politik International: List of current political news headlines\n",
    "* 11) (Achtung - Sonderdisposition): List of articles on a particular topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nutzer\\anaconda3\\lib\\site-packages\\pandas\\core\\strings\\accessor.py:101: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3511650\n"
     ]
    }
   ],
   "source": [
    "fill_text = '''Schalterverkaufskurse:|dpa-news\\.de|Wirtschafts- und Finanztermine|Wirtschafts- und Finanz-Termine|DGAP|Bitte verwenden Sie diese Meldung nicht|Konjunktur- und Wirtschaftstermine|\\(Wiederholung|[§] 26 Abs\\. 1|§ 15a WpHG|§ 15 WpHG|Artikel 19 MAR|article 19 Market Abuse Regulation \\(MAR\\)|Die Pivotpunkte für den Dax-Future|An der Frankfurter Wertpapierbörse wurden|Die Aktien im Dow Jones EuroStoxx 50|Die Aktien im Dow Jones Euro Stoxx 50|\\(Achtung - Sonderdisposition\\)'''\n",
    "text_exc = '''Auswärtige Politik'''\n",
    "data.drop(data[(data['texts'].str.contains(fill_text, na = False)) & (~data['texts'].str.contains(text_exc, na=False))].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to exclude non-economic articles based on the following two sources.\n",
    "* 1) dpa-frei: Article corrections\n",
    "* 2) dpa-wahl: Articles about federal election results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3511626\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[data['source'].str.contains('dpa-frei|dpa-wahl', na = False)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We exclude articles regarding dpa itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3511622\n"
     ]
    }
   ],
   "source": [
    "data.drop(data[data['city'].str.contains('Die Deutsche Presse-Agentur', na = False)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes multiple articles are collected and merged into one entry. For example, articles with the title, keyword, or genre \n",
    "'Nachrichtenüberblick' are a collection of the most important articles of the day. Because these smaller articles\n",
    "can have different sentiments and topics, we separate articles that consist of multiple smaller articles. Articles consisting of multiple smaller articles can be identified with the following words which can appear in titles, keywords, or genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dpa-Nachrichtenüberblick, Nachrichtenüberblick: List of news for the upcomming days or from news which are a few days old\n",
    "- Vorschau, vorschau, VORSCHAU: List of news for the upcomming days\n",
    "- Die Woche in Berlin (1999-2018), Die Woche in Bonn (1991-1999): News regarding the parlament from last week. \n",
    "- Aus der Landespolitik - Kurz gemeldet: Collection of short political articles regarding regional politics\n",
    "- Die politische Woche: Announcments of Political (and Economical) news for next week\n",
    "- Kurznachrichten Wirtschaft: Collection of short economic news\n",
    "- Wochenvorschau: List of news for the upcoming week\n",
    "- Analysten-Einstufungen, ANALYSTEN-EINSTUFUNGEN:\n",
    "- Notizen aus der Politik, NOTIZEN AUS DER POLITIK, Notizen aus der Politik: Collection of varios short political articles \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_mult_art = '''dpa-Nachrichtenüberblick|Nachrichtenüberblick|Die Woche in Berlin|Die Woche in Bonn|Aus der Landespolitik - kurz gemeldet|Die politische Woche|Kurznachrichten Wirtschaft|Wochenvorschau|Analysten-Einstufungen|ANALYSTEN-EINSTUFUNGEN|Notizen aus der Politik|NOTIZEN AUS DER POLITIK'''\n",
    "mult_art = data[data['title'].str.contains(s_mult_art, na = False)]\n",
    "mult_art = mult_art.append(data[data['keywords'].str.contains(s_mult_art, na = False)])\n",
    "mult_art = mult_art.append(data[data['genre'].str.contains(s_mult_art, na = False)])\n",
    "mult_art.drop_duplicates(['texts'], keep = 'first', inplace=True)\n",
    "mult_art.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete 'mult_art' from the original data\n",
    "data.drop(data[data['title'].str.contains(s_mult_art, na = False)].index, inplace=True)\n",
    "data.drop(data[data['keywords'].str.contains(s_mult_art, na = False)].index, inplace=True)\n",
    "data.drop(data[data['genre'].str.contains(s_mult_art, na = False)].index, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate chunck size \n",
    "chunk_size = int(mult_art.shape[0]/NUM_CORE)\n",
    "\n",
    "# split data into chunks \n",
    "chunks = [mult_art.iloc[mult_art.index[i:i + chunk_size]] for \n",
    "          i in range(0, mult_art.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:07:44.690301\n"
     ]
    }
   ],
   "source": [
    "# split up articles in into smaller articles and append the resulting new articles \n",
    "# to the corpus\n",
    "from datetime import datetime\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    results = pool.map(split_articles.split_articles, chunks) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)\n",
    "\n",
    "results = pd.concat(results)\n",
    "print(len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The separated articles consist of fewer words than the articles from which they originally stemmed. Therefore, we count the number of words of the new articles with the count_words_mp function from before and filter out articles with less than 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:09.189036\n"
     ]
    }
   ],
   "source": [
    "# count the number of words for the seperated articles and filter out articles with less\n",
    "# than 100 words\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    count_results = pool.map(count_words_mp.count_words_mp, [text for text in results['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['word_count'] = count_results\n",
    "results = results[results['word_count']>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2031724\n"
     ]
    }
   ],
   "source": [
    "# append seperated articles to corpus\n",
    "data = data.append(results)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and Delete English Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:48:39.715753\n"
     ]
    }
   ],
   "source": [
    "# Delete all English articles from the data  \n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    eng_results = pool.map(identify_eng_2.identify_eng_2, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064333\n"
     ]
    }
   ],
   "source": [
    "data['language'] = eng_results\n",
    "data = data[data.language==0]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify articles that predominantly consist of numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Articles that consist predominately of numbers sometimes carry little sentiment. Filtering out all numbers only helps a little, because the resulting texts are often grammatical nonsensical. To get a better understanding of how these articles look we identify all articles that consist of more than 80% of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:01:23.476436\n"
     ]
    }
   ],
   "source": [
    "# use the 'numeric_articles' function to identify economic articles with a high share of numbers in them\n",
    "inputs = zip(data['texts'], data['word_count'], itertools.repeat(0.80))\n",
    "\n",
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    numeric_list = pool.starmap(numeric_articles.numeric_articles, inputs)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = data[numeric_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FLENSBURG (dpa-AFX) - Der langjährige Renner VW-Golf <VOW.ETR> ist auch 1999 an der Spitze der Auto-Neuzulassungen in Deutschland geblieben. Den 356.000 Golf-Exemplaren - einschließlich seiner Abwandlungen Vento und Bora - folgten erneut rund 230.000 Opel-Astra <GM.NYS>. Das geht aus einer Statistik der Kraftfahrt-Bundesamts (KBA) in Flensburg hervor, die am Dienstag veröffentlicht wurde. Insgesamt kamen 1999 knapp über 3,8 Millionen fabrikneue Personenwagen in den Straßenverkehr. 1998 waren es 3,73 Millionen.      Auf den dritten Platz liegen mit 143.000 Erstanmeldungen die Fahrzeugtypen der Dreier-Reihe von BMW <BME.ETR>, die den ebenfalls seit Jahren mit führenden VW-Passat (136.500) auf den vierten Rang verdrängten. Neuling in der 1999er Tabellenspitze der 25 Wagentypen - von insgesamt über 70 - sind der Ford-Focus <F.NYS> auf Platz fünf mit 113.000 Neuzulassungen, der VW-Lupo (16./61.000), der Peugeot 206 (22./44.000) sowie der Opel-Zafira (25./38.500). Auf Erfolgskurs ist auch die an siebter Stelle platzierte A-Klasse (100.000) von Mercedes/DaimlerChrysler <DCX.ETR>.    Die 25 Erstplatzierten der Pkw-Neuzulassungen 1999 (in Klammern 1998):  1. VW-Golf/Vento/Bora    356 246   ( 1. 347.151)  2. Opel-Astra            229 756   ( 2. 220.095)  3. BMW-Dreier            143 103   ( 6. 123.937)  4. VW-Passat             136 486   ( 3. 160.127)  5. Ford-Focus            112 873   (55.   9.256)  6. Opel-Corsa            111 781   ( 4. 128.141)  7. Mercedes A-Klasse     100 376   (16.  76.443)  8. Audi A4                97 976   ( 9. 101.935)  9. Opel-Vectra            94 057   ( 5. 124.645) 10. VW-Polo                90 858   ( 6. 106.341) 11. Mercedes E-Klasse      90 603   (10.  93.449) 12. Mercedes C-Klasse      89 909   ( 7. 112.513) 13. Renault-Megane         89 845   (11.  88.417) 14. BMW-Fünfer             69 552   (13.  81.904) 15. Audi A6                69 176   (17.  70.428) 16. Audi A3                61 237   (18.  59.923) 17. VW-Lupo                60 965   (47.  18.500) 18. Renault-Twingo         54 832   (19.  58.495) 19. Ford-Fiesta            53 213   (14.  78.660) 20. Ford-Mondeo            47 712   (12.  84.781) 21. Renault-Clio           46 234   (28.  30.524) 22. Peugeot 206            43 836   (56.   8.138) 23. Fiat-Punto             42 312   (21.  55.491) 24. VW-Transporter         40 068   (24.  37.825) 25. Opel-Zafira            38 584   (        122) /fc/ba/DP'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect example article with high share of numbers\n",
    "numeric['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operative Kosten                        40.616     48.002    18,2% Vertriebs- und allg.                    25.892     36.359    40,4% Verwaltungskosten Zentrale Verwaltungskosten              16.114     18.884    17,2% Nicht liquiditätswirksame                    0      5.393 Personalkosten aus der Gewährung von Aktienoptionen Abschreibungen und Amortisierung       122.614    119.848    -2,3% ------------------------------------------------------------------ --- Betriebsaufwand                        205.236    228.486    11,3% ------------------------------------------------------------------ --- ------------------------------------------------------------------ --- Betriebsergebnis (-verlust)            -21.193    -21.268     0,4%  ------------------------------------------------------------------ --- Zinsaufwand                            -55.901    -31.046   -44,5% Anderer Aufwand                         -1.298     -1.500    15,6% ------------------------------------------------------------------ --- Gewinn (Verlust) aus der gewöhnl.      -78.392    -53.814   -31,4% Geschäftstätigkeit vor Anteilen von Minderheitsgesellschaftern ------------------------------------------------------------------ --- Anteile von                               -584       -137   -76,5% Minderheitsgesellschaftern Ertragssteuern                          -3.835     -3.260   -15,0% ------------------------------------------------------------------ --- ERGEBNIS DER GEWÄHL.                   -82.811    -57.211   -30,9% GESCHÄFTSTÄTIGKEIT ------------------------------------------------------------------ --- Eingestellte Unternehmensbereiche       -3.469          0  -100,0% ------------------------------------------------------------------ --- Nettogewinn (-verlust)                 -86.280    -57.211   -33,7% ------------------------------------------------------------------ --- EBITDA                                 100.123     97.081    -3,0% EBITDA-Marge                             54,4%      46,8%  EBITDA (angepasst)                     101.421    103.974     2,5% EBITDA Marge (angepasst)                 55,1%      50,2%  Durchschn. Video Teilnehmer            793.715    907.574    14,3% Durchschn, Umsatzerlös pro               19,32      19,03    -1,5% Teilnehmer (DM) PrimaComAG, Hegelstr. 61, 55122 Mainz Tel++49-6131-93100  PrimaCom AG und Tochterunternehmen Konzernbilanzen (in tausend)                                       1998 (DM)        1999 (DM)  Flüssige Mittel                          15.347           16.365 Forderungen aus Lieferungen und           5.444            7.265 Leistungen Latente Steuerguthaben                   87.678           92.522 Sachanlagen                             544.393          541.351 Geschäfts- oder Firmenwert              473.600          467.150 Devisentermingeschäfte                   20.807                - Sonstige Vermögensgegenstände            44.280           22.708 Nettovermögen der zu verkaufenden             -                - Geschäftsbereiche ------------------------------------------------------------------ AKTIVA                                1.191.549        1.147.361 ------------------------------------------------------------------  Verbindlichkeiten aus Lieferungen         8.990           11.353 und Leistungen Rückstellungen                           51.732           28.946 Passive Rechnungsabgrenzungsposten        9.603           24.630 Ausstehende Kaufpreisverpflichtung        6.627            4.507 Leasingverbindlichkeiten                 86.382           27.620 Verbindlichkeiten gegenüber den             516              480 der Gesellschaft nahestehenden Personen oder Unternehmen Verbindlichkeiten gegenüber             281.395          406.990 Kreditinstituten und anderen Verbindlichkeiten Senior Notes                            275.981                - ------------------------------------------------------------------- SUMME DER VERBINDLICHKEITEN             721.226          504.526 ------------------------------------------------------------------- Minderheitenanteile                         862              165 Stammkapital                             78.914           98.643 Kapitalrücklage                         473.982          684.672 Verlustvortrag                          -83.435         -140.645 ------------------------------------------------------------------- EIGENKAPITAL/(NICHT DURCH               469.461          642.670 EIGENKAPITAL GEDECKTER FEHLBETRAG) ------------------------------------------------------------------- ------------------------------------------------------------------- PASSIVA                               1.191.549        1.147.361 ------------------------------------------------------------------- Ende der Mitteilung'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric['texts'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5412"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge continuations of articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some dpa-afx articles are split into multiple entries marked by the word 'Fortsetzung' at the beginning of the texts of following entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FRANKFURT (dpa-AFX) - Der deutsche Aktienmarkt hat am Montag für wenige Augenblicke seinen Rekordschluss vom Juli 1998 überschritten. Mit einem Höchststand von 6.188,68 lag der Dax über dem Tageschluss vom 21. Juli 1998, als der Index 6.186 Punkte erreichte. Der Dax <DAX.ETR> schloss den Handel am ersten Wochentag bei 6.142,19 Zählern und damit um 0,38% oder 23,02 Punkte fester ab. Der Nebenwerteindex M-Dax <MDAX.ETR> gab dagegen auf 3.990,00 Punkte oder um 1,43% nach, und der Neue Markt-Index Nemax 50 <NMKX.ETR> schloss bei 4.610,66 Zählern (-0,58%).      Spätestens auf dem Niveau des All-Time-High bei ungefähr 6.200 Punkten werde der Index auf einen massiven Widerstand stoßen, heißt es am Montag in einem Research-Report von der Nürnberger Schmidt Bank. Michael Schubert, Analyst der Bankgesellschaft Berlin, sagte in einem Gespräch mit dpa-AFX, derzeit sei der einzig negative Faktor, dass die Börse nicht von der Breite getragen werde, sondern nur von wenigen Titeln. Wer jetzt noch nicht investiert habe, sei in einer unangenehmen Situation: Er müsse dem Markt hinterherlaufen. Nach Meinung von Schubert ist eine Konsolidierung bis auf einen Wert von 6.000 oder 5.800 Zähler durchaus sinnvoll. Der Rückschritt soll sich am Besten ein bis zwei Wochen hinziehen, sagte Schubert./mr/ba'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texts'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Fortsetzung) - Der Tagesgewinner SAP <SAP.ETR> übernahm bereits am Vormittag die Führung bei den Gewinnern ein und schloss den Handel mit einem Kurszuwachs von 6,27% auf 475,20 Euro ab. Händler waren sich einig darüber, dass SAP weiteres Wachstumpotenzial haben. Ende vergangener Woche habe es Kaufempfehlungen für das Papier gegeben, sagte ein Händler. Die ABN Amro Bank hatte ihr Kursziel mit 600 Euro festgesetzt.      Den Wert umgaben zudem Gerüchte über eine bevorstehende Allianz mit einem Weltkonzern, hieß es. Ein anderer Händler hielt den aktuellen SAP-Kurs noch immer für zu billig. Wachstumswerte stünden weiter in der Gunst der Anleger. Bei SAP hätten Image und Aktienkurs unter Problemen in den USA gelitten. Das werde nach Erwartung des Händlers aber spätestens mit den Geschäftszahlen des ersten Quartals 2000 überwunden sein. Mit dem Ende der Angst vor dem Jahr-2000-Problem würde der Kurs weiter steigen.     Ihren Kurshöhenflug fortsetzen konnten zudem die Aktien von Siemens <SIE.ETR>. Sie schlossen den Handel um 4,94% fester bei 114,70 Euro. Der Technologiekonzern hatte am Vormittag bekannt gegeben, dass das Unternehmen seinen Atombereich mit der französischen Framatome zusammenlegen will. An dem Joint Venture soll Framatome 66%, Siemens wird 34% der Anteile halten. Für Alexander Koch von der KBC Bank Deutschland unterstützt diese Meldung den positiven Trend bei Siemens. Das ist jener Dax-Wert, der charttechnisch zur Zeit am besten aussieht, sagte er.     Die Aktie der Mannesmann AG <MMN.ETR> hat sich nach einer Klage der Mannesmann-Aktionäre gegen das eigene Management am Montag ebenfalls fest präsentiert. Der Titel schloss bei einem Kurs von 235,00 Euro und damit 4,44% fester. Gegen die Werbekampagne von Mannesmann bei Anlegern und Investoren, mit der eine Übernahmen durch Vodafone Airtouch <VOD.ISS> verhindert werden soll, sind inzwischen einige Aktionäre gerichtlich vorgegangen.(...)/mr/fs'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texts'].iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Fortsetzung) - Überraschend fest tendierten am Montag die Autowerte. Volkswagen <VOW.ETR> gewannen 1,6% auf 49,35 Euro. Vielleicht sehen wir jetzt tatsächlich eine Branchen-Rotation zur Autobranche hin, sagte ein Händler der DG-Bank. Die nahe Zukunft des Wertes stehe oder falle mit der 50 Euro Marke. Auch BMW <BMW.ETR> (28,10 Euro/+1,04%) und DaimlerChrysler <DCX.ETR> (67,25 Euro/+0,67%)  verbuchten Kurszuwächse. Alle drei deutschen Hersteller verbuchten einem Pressebericht zufolge im Gesamtjahr 1999 steigende Absatzzahlen in den USA.       Die Verliererliste führten am Montag Lufthansa <LHA.ETR> (22,30 Euro/-3,88%) und Veba <VEB.ETR> (45,47 Euro/-3,87%) an. Unter Gewinnmitnahmen litt laut Händlern der Kurs der T-Aktie <DTE.ETR>: Der Titel verlor im Montagshandel 1,31% auf 59,30 Euro. Wäre die Telekom mit dem Indextrend im Wert gestiegen, hätte der Dax den Rekordstand vom Juli 1998 eingestellt, rechnete ein Händler am Nachmittag vor./mr/fs'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['texts'].iloc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identify which entries belong together and merge them to one article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into roughly equal sized chunks where articles from one day only fall under the same chunk\n",
    "data_cont = data[data['topic'] == 'afx']\n",
    "dates = data_cont.groupby(['year', 'month', 'day'])\n",
    "dates = list(dates.groups)\n",
    "dates = np.array_split(dates, NUM_CORE)\n",
    "\n",
    "meta_data = data_cont.loc[:, data_cont.columns != 'texts']\n",
    "\n",
    "chunks = [pd.concat([data_cont[(data_cont['year'] == t[0]) & (data_cont['month'] == t[1]) & (data_cont['day'] == t[2])] for t in tup]) for tup in dates]\n",
    "chunks = [[chunk, meta_data] for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:14:56.636717\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    continue_results = pool.map(continue_articles.continue_articles, chunks) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(list(itertools.chain(*[tup[0] for tup in continue_results])), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_articles = pd.concat([tup[1] for tup in continue_results])\n",
    "print(len(continue_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974426\n"
     ]
    }
   ],
   "source": [
    "data = data.append(continue_articles)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:06:33.551105\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    url_corrected = pool.map(correct_url.correct_url, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = url_corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove dpa references"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove dpa references (e.g. NEW YORK (dpa) - ...) from each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:15:15.393896\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    dpa_ref_removed = pool.map(clean_dpa_references.clean_dpa_references, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = dpa_ref_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step7.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umlauts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Older articles (1991 - 2000) from the section 'Kommentar' (Commentary) are often missing umlauts and correct capitalization. To\n",
    "fix these two issues, we use the notebook Umlauts_fix written in Python 2 and the notebook Truecasing written in Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "umlauts = ['ä', 'ö', 'ü', 'ß', 'Ä', 'Ö', 'Ü']\n",
    "umlauts_replace = ['ae', 'oe', 'ue', 'ss', 'AE', 'OE', 'UE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_umlauts_fix = data[(data.texts.str.contains('|'.join(umlauts_replace))) & (~data.texts.str.contains('|'.join(umlauts))) & (data.year<2001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ad-hoc announcement sent by DGAP. The sender is solely responsible for the contents of this announcement.  Ad-hoc Mitteilung Nach @ 15 WpHG  WizCom Technologies Ltd. (WizCom) <WZM.FSE> (Neuer Markt:WZM,WKN:915 856) veroeffentlicht das Ergebnis fuer das am 31. Dezember 1999 endende Geschaeftsjahr 20. Maerz 2000, Jerusalem, Israel - Der Umsatz belief sich im Jahr 1999 auf US$ Mio. 11,613. Der Vorjahreswert lag bei US$ Mio. 15,799. Der Umsatz im ersten bzw. zweiten Halbjahr 1999 betrug US$ Mio. 4,046 bzw. US$ Mio. 7,567. Das Unternehmen sieht den Umsatzrueckgang als voruebergehend an und vor allem im zweiten Halbjahr begruendet, weil das neue Produkt, der QuickLink-Pen, erst mit einigen Monaten Verzoegerung auf den Markt gebracht werden konnte. Im 4. Quartal 1999 konnte WizCom den QuickLink Pen in den USA erfolgreich auf den Markt bringen. Im 1. Quartal 2000 vermarktet WizCom den QuickLink Pen in weiteren Laendern, unter anderem Australien, Grossbritannien, Deutschland und Frankreich. Der Bruttogewinn verringerte sich von US$ Mio. 5,503 im Jahr 1998 auf US$ Mio. 3,221 im Jahr 1999. Dies ist hauptsaechlich auf den voruebergehenden Rueckgang beim Umsatz und auf die Fixkosten fuer das neue Produkt, den QuickLink-Pen, zurueckzufuehren. Der Nettoverlust fuer das Jahr 1999 betrug US$ Mio. 11,692, gegenueber US$ Mio. 4,130 in 1998. Hierin enthalten ist die einmalige Rueckzahlung eines Disagios auf Wandel-schuldverschreibungen in Hoehe von US$ Mio. 4,659 sowie eine Abschreibung auf  laufende Forschungs- und Entwicklungsarbeiten in Hoehe von US$ Mio. 2,271. WizCom ist ein Weltmarktfuehrer im Bereich der tragbaren Datenerfassungstechnologien. WizCom produziert und vermarktet die Produkte der Quicktionary Produktfamilie - tragbare stiftfoermige Scanner fuer den Linguistik- und Lehrmitttelmarkt. WizCom verfuegt ueber die einzigartige OCR (Optical Character Resolution)- Technologie, die in den Produkten implementiert sind. Seit Januar 2000 hat Wizcom seine Produktreihe um die erste Generation der Quicktionary Produkte, das Quicktionary II und den QuickLink-Pen, erweitert. Wizcom erwartet ein deutliches Umsatzwachstum sowohl im ersten Quartal 2000, als auch fuer den Rest des Jahres. Die Umsatzsteigerung wird zum einen auf dem Verkauf des QuickLink-Pen in den USA und weltweit basieren, zum anderen auf der Vermarktung des Quicktionary II nach der erwarteten Markteinfuehrung im 2. Quartal 2000. Zusaetzliche Einnahmen wird der Verkauf der Wizcom Plug- ins fuer Mobiltelefone im 4. Quartal bringen. Vor Kurzem hat Wizcom ein Lizenzabkommen mit Ericsson angekuendigt. Dieses Abkommen ermoeglicht es Wizcom, Technologie von Ericsson bei der Entwicklung von Plug-ins fuer Mobiltelefone von Ericsson zu verwenden. Mit diesen Plug-ins koennen Besitzer von Mobiltelefonen auf Papier vorliegenden Text direkt in ihr Mobiltelefon einscannen und so Daten speichern, via WAP dem Internet zur Verfuegung stellen oder per SMS versenden. Weitere Anwendungen werden entwickelt. Dieses Abkommen ist ein weiterer Schritt auf Wizcoms Weg zur Marktfuehrung im Sektor der tragbaren Datenlesegeraete und zur weiteren Verbreitung seiner Scann- und Texterkennungstechnologien im Marktsegment der tragbaren Geraete. Nach dem Abkommen mit Ericsson haben auch andere namhafte Hersteller und Serviceanbieter mit Wizcom Kontakt aufgenommen, um Wege fuer den Einsatz dieser innovativen Technologie zu finden.  Ende der Mitteilung'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa_umlauts_fix['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_umlauts_fix.to_csv('dpa_umlauts_fix.csv', encoding='utf-8-sig', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_umlauts_fixed = pd.read_csv('dpa_umlauts_fixed.csv', encoding = 'utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truecasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_cases_fix = data[data.texts.str.contains('^(?!.*[A-Z])')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new york (vwd) - enttaeuschend verlief das geschaeft am mittwoch, dem ersten handelstag im neuen jahr, an der new yorker aktienboerse. die zunaechst gesehenen leichten gewinne konnten nur bis in das fruehe nachmittagsgeschaeft behauptet werden. in den letzten 2-1/2 geschaeftststunden gerieten die kurse in die minuszone und wall street schloss auf breiter front schwaecher. der dow-jones-index fuer 30 industriewerte gab um 23,02 auf 2.610,64 punkte nach. auch die uebrigen marktbestimmenden indizes gerieten in die minuszone. bei einem umsatz von 126,28 (114,13) millionen aktien standen die kursverlierer den -gewinnern im verhaeltnis von rund neun zu sieben gegenueber. verantwortlich fuer die schwaeche waren wiederauflebende befuerchtungen ueber eine anhaltende rezessionsphase. nachdem sogar das weisse haus jetzt von einer rezessionaeren entwicklung spricht, hielten sich die meisten anleger mit ihren engagements zurueck, wodurch der vorherrschende abgabedruck ausreichte, um die kurse in die minuszone zu treiben. vor allem neue konjunktureckdaten, die auf eine rezession hindeuten, standen hinter der abwaertsbewegung. bei vielen anlegern setzte sich die befuerchtung durch, dass die schwache konjunktur zu einer schmaelerung der unternehmensertraege fuehren werde. vwd/2.1.91/06/mp/hs'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpa_cases_fix['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_cases_fix.to_csv('dpa_case_fix.csv', encoding='utf-8-sig', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpa_cases_fixed = pd.read_csv('dpa_cases_fixed.csv', encoding = 'utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[dpa_cases_fixed.index, 'texts'] = dpa_cases_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York( Vwd)- Enttaeuschend verlief das Geschaeft am Mittwoch, dem ersten Handelstag im neuen Jahr, an der New Yorker Aktienboerse. Die Zunaechst Gesehenen leichten Gewinne konnten nur bis in das Fruehe Nachmittagsgeschaeft behauptet werden. In den letzten 2-1/2 Geschaeftststunden gerieten die Kurse in die Minuszone und Wall Street schloss auf breiter Front Schwaecher. Der Dow-Jones-Index Fuer 30 Industriewerte gab um 23,02 auf 2.610,64 Punkte nach. Auch die Uebrigen Marktbestimmenden Indizes gerieten in die Minuszone. Bei einem Umsatz von 126,28( 114,13) Millionen Aktien standen die Kursverlierer den -Gewinnern im Verhaeltnis von rund neun zu sieben Gegenueber. Verantwortlich Fuer die Schwaeche waren Wiederauflebende Befuerchtungen Ueber eine anhaltende Rezessionsphase. Nachdem sogar das Weisse Haus jetzt von einer Rezessionaeren Entwicklung spricht, hielten sich die meisten Anleger mit ihren Engagements Zurueck, wodurch der vorherrschende Abgabedruck ausreichte, um die Kurse in die Minuszone zu treiben. Vor allem neue Konjunktureckdaten, die auf eine Rezession hindeuten, standen hinter der Abwaertsbewegung. Bei vielen Anlegern setzte sich die Befuerchtung durch, dass die schwache Konjunktur zu einer Schmaelerung der Unternehmensertraege Fuehren werde. Vwd/2.1.91/06/Mp/Hs'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fixed version\n",
    "data['texts'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing tokens containing a number and a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In quite a few cases, a number and a word are erroneously merged into a single token. Splitting these tokens into two tokens helps us to deal with the following problems:\n",
    "\n",
    "(see Handelsblatt notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:02:13.158789\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "\n",
    "import split_number_word\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    split_corrected = pool.map(split_number_word.split_number_word, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = split_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step8.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Fuzzy Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_keep = ['russische Aktienmarkt', 'europäischen Börsen', 'Deutsche Börse' ,'Europäische Zentralbank',\n",
    "'Moskauer Aktienmarkt', 'deutsche Aktienmarkt', 'deutschen Aktienmarkt', 'Folgende Investmentbanken',\n",
    "'deutsche Rentenmarkt', 'amerikanischen Treasury Bonds', 'IRW-PRESS', 'Deutsche Bank', 'Ausgewählte Analysten-Einstufungen',\n",
    "'Deutsche Staatsanleihen', 'Der japanische Aktienmarkt']\n",
    "\n",
    "exceptions = ['NO_EXCEPTIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991.0\n",
      "1992.0\n",
      "1993.0\n",
      "1994.0\n",
      "1995.0\n",
      "1996.0\n",
      "1997.0\n",
      "1998.0\n",
      "1999.0\n",
      "2000.0\n",
      "2001.0\n",
      "2002.0\n",
      "2003.0\n",
      "2004.0\n",
      "2005.0\n",
      "2006.0\n",
      "2007.0\n",
      "2008.0\n",
      "2009.0\n",
      "2010.0\n",
      "2011.0\n",
      "2012.0\n",
      "2013.0\n",
      "2014.0\n",
      "2015.0\n",
      "2016.0\n",
      "2017.0\n",
      "2018.0\n",
      "6:58:11.847691\n"
     ]
    }
   ],
   "source": [
    "# import a function that outputs the indices of duplicates \n",
    "import fuzzy_duplicates\n",
    "delete_indices = []\n",
    "startTime = datetime.now() \n",
    "for year in list(set(data['year'])):\n",
    "    data_input = data[(data['year'] == year)]\n",
    "    for month in list(set(data_input[data_input['year'] == year]['month'])): # old: list(set(data))\n",
    "            # Prepare inputs\n",
    "            inputs_year = []\n",
    "            inputs_month = []\n",
    "            inputs_month_year = []\n",
    "            inputs_year.append(year)\n",
    "            inputs_month.append(month)\n",
    "            inputs_month_year.append(data_input[(data_input['year'] == year) & (data_input['month'] == month)][[\"month\", \"year\", \"texts\"]])\n",
    "\n",
    "            #from itertools import repeat\n",
    "            inputs = list(zip(inputs_year, inputs_month, inputs_month_year))\n",
    "            from datetime import datetime\n",
    "            if __name__ == \"__main__\":\n",
    "                pool = mp.Pool(NUM_CORE)\n",
    "                # apply function to all combinations of month-year in parallel\n",
    "                delete_intermediate = pool.starmap(fuzzy_duplicates.fuzzy_duplicates, zip(inputs, repeat(types_keep), repeat(exceptions)))\n",
    "                delete_indices = delete_indices + delete_intermediate # create one list of indices\n",
    "                pool.close()\n",
    "                pool.join()  \n",
    "    print(year)\n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_indices = list(set([item for sublist in delete_indices for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1580324\n"
     ]
    }
   ],
   "source": [
    "data.drop(delete_indices, inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_step9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dpa articles include some unnecessary text passages like inquiry notes or references to webpages. We decided to clean the \n",
    "affected articles from these text passages to make the sentiment classification easier for our model(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove the following terms and sections from the texts:\n",
    "* 1) stock symbols\n",
    "* 2) additional metadata in the text meant for the author\n",
    "* 3) references to previos articles\n",
    "* 4) references to dpa and dpa-AFX webpage\n",
    "* 5) uncorrected original article on which a correction is based on\n",
    "* 6) inquiry notes\n",
    "* 7) reference to english article on which some articles are based on\n",
    "* 8) date of the article\n",
    "* 9) references for aditional information (phone numbers, webpages etc.)\n",
    "* 10) references to sender\n",
    "* 11) references to Debitos\n",
    "* 12) references to issuer\n",
    "* 13) reference to authors\n",
    "* 14) references to summary of article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:58:52.745164\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "if __name__ == \"__main__\":\n",
    "    pool = mp.Pool(NUM_CORE)\n",
    "    cleaned_articles = pool.map(clean_dpa_articles.clean_dpa_articles, [text for text in data['texts']]) \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "print(datetime.now()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['texts'] = cleaned_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('dpa_prepro_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
